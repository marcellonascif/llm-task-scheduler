{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "379d5361",
   "metadata": {},
   "source": [
    "# Pr√© processamento do dataset de tarefas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "29fcfc92",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8fed6f22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV carregado com engine C! 7232 linhas encontradas.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    df = pd.read_csv(\n",
    "        '../data/tasks.csv',\n",
    "        encoding='utf-8',\n",
    "        sep=\",\",\n",
    "        quotechar='\"',\n",
    "        on_bad_lines='skip',      # ignora linhas corrompidas\n",
    "        dtype=str,               # carrega tudo como string, depois ajusta\n",
    "        engine='c'          # usa engine python que √© mais tolerante\n",
    "    )\n",
    "    print(f\"CSV carregado com engine C! {len(df)} linhas encontradas.\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Erro ao ler CSV: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0a06b66e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== INFORMA√á√ïES B√ÅSICAS DO DATASET ===\n",
      "Shape: (7232, 17)\n",
      "\n",
      "Tipos de dados:\n",
      "SUMMARY                          object\n",
      "DTSTART                          object\n",
      "DTEND                            object\n",
      "DUE                              object\n",
      "NOTES                            object\n",
      "ATTENDEE                         object\n",
      "LOCATION                         object\n",
      "PRIORITY                         object\n",
      "URL                              object\n",
      "CALENDAR                         object\n",
      "UID                              object\n",
      "ORGANIZER                        object\n",
      "CATEGORIES                       object\n",
      "DURATION                         object\n",
      "REPLACES RECURRENT EVENT FROM    object\n",
      "CANCELLED                        object\n",
      "CREATED                          object\n",
      "dtype: object\n",
      "\n",
      "Primeiras 5 linhas:\n",
      "  SUMMARY           DTSTART             DTEND  DUE NOTES ATTENDEE LOCATION  \\\n",
      "0       üç≥  07/01/2025 08:00  07/01/2025 08:20  NaN   NaN      NaN      NaN   \n",
      "1       üßã  07/01/2025 10:00  07/01/2025 10:05  NaN   NaN      NaN      NaN   \n",
      "2      üçΩÔ∏è  07/01/2025 12:30  07/01/2025 13:00  NaN   NaN      NaN      NaN   \n",
      "3       ü•™  07/01/2025 16:00  07/01/2025 16:15  NaN   NaN      NaN      NaN   \n",
      "4       üçå  07/01/2025 18:00  07/01/2025 18:05  NaN   NaN      NaN      NaN   \n",
      "\n",
      "  PRIORITY  URL     CALENDAR  UID ORGANIZER CATEGORIES           DURATION  \\\n",
      "0      NaN  NaN  Alimenta√ß√£o  NaN       NaN        NaN   0.33333333333333   \n",
      "1      NaN  NaN  Alimenta√ß√£o  NaN       NaN        NaN  0.083333333333333   \n",
      "2      NaN  NaN  Alimenta√ß√£o  NaN       NaN        NaN                0.5   \n",
      "3      NaN  NaN  Alimenta√ß√£o  NaN       NaN        NaN               0.25   \n",
      "4      NaN  NaN  Alimenta√ß√£o  NaN       NaN        NaN  0.083333333333333   \n",
      "\n",
      "  REPLACES RECURRENT EVENT FROM CANCELLED           CREATED  \n",
      "0                           NaN       NaN  07/01/2025 10:12  \n",
      "1                           NaN       NaN  07/01/2025 10:14  \n",
      "2                           NaN       NaN  07/01/2025 10:15  \n",
      "3                           NaN       NaN  07/01/2025 10:16  \n",
      "4                           NaN       NaN  07/01/2025 10:17  \n",
      "\n",
      "Valores nulos por coluna:\n",
      "SUMMARY                             0\n",
      "DTSTART                             0\n",
      "DTEND                               2\n",
      "DUE                              7232\n",
      "NOTES                            6657\n",
      "ATTENDEE                         7193\n",
      "LOCATION                         5457\n",
      "PRIORITY                         7232\n",
      "URL                              7232\n",
      "CALENDAR                            0\n",
      "UID                              7232\n",
      "ORGANIZER                        7204\n",
      "CATEGORIES                       7232\n",
      "DURATION                            2\n",
      "REPLACES RECURRENT EVENT FROM    7145\n",
      "CANCELLED                        7047\n",
      "CREATED                             0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Verificar informa√ß√µes b√°sicas do dataset\n",
    "if df is not None:\n",
    "    print(\"=== INFORMA√á√ïES B√ÅSICAS DO DATASET ===\")\n",
    "    print(f\"Shape: {df.shape}\")\n",
    "    print(f\"\\nTipos de dados:\")\n",
    "    print(df.dtypes)\n",
    "    print(f\"\\nPrimeiras 5 linhas:\")\n",
    "    print(df.head())\n",
    "    print(f\"\\nValores nulos por coluna:\")\n",
    "    print(df.isnull().sum())\n",
    "else:\n",
    "    print(\"DataFrame n√£o foi carregado corretamente.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "541c8837",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== AN√ÅLISE DAS COLUNAS DE DATA ===\n",
      "\n",
      "DTSTART:\n",
      "  - Valores √∫nicos (sample): ['07/01/2025 08:00' '07/01/2025 10:00' '07/01/2025 12:30'\n",
      " '07/01/2025 16:00' '07/01/2025 18:00']\n",
      "  - Valores nulos: 0\n",
      "  - Total n√£o-nulos: 7232\n",
      "\n",
      "DTEND:\n",
      "  - Valores √∫nicos (sample): ['07/01/2025 08:20' '07/01/2025 10:05' '07/01/2025 13:00'\n",
      " '07/01/2025 16:15' '07/01/2025 18:05']\n",
      "  - Valores nulos: 2\n",
      "  - Total n√£o-nulos: 7230\n",
      "\n",
      "DUE:\n",
      "  - Valores √∫nicos (sample): []\n",
      "  - Valores nulos: 7232\n",
      "  - Total n√£o-nulos: 0\n",
      "\n",
      "CREATED:\n",
      "  - Valores √∫nicos (sample): ['07/01/2025 10:12' '07/01/2025 10:14' '07/01/2025 10:15'\n",
      " '07/01/2025 10:16' '07/01/2025 10:17']\n",
      "  - Valores nulos: 0\n",
      "  - Total n√£o-nulos: 7232\n",
      "\n",
      "=== COLUNAS CATEG√ìRICAS ===\n",
      "\n",
      "CALENDAR:\n",
      "CALENDAR\n",
      "Alimenta√ß√£o    2323\n",
      "Trabalho       1255\n",
      "PUC            1219\n",
      "Exerc√≠cios      870\n",
      "Pessoal         564\n",
      "PUC üëª           514\n",
      "Sa√∫de           171\n",
      "Exames          117\n",
      "Social           52\n",
      "Compromisso      49\n",
      "Name: count, dtype: int64\n",
      "\n",
      "CATEGORIES:\n",
      "Series([], Name: count, dtype: int64)\n",
      "\n",
      "PRIORITY:\n",
      "Series([], Name: count, dtype: int64)\n"
     ]
    }
   ],
   "source": [
    "# Analisar as colunas de data especificamente\n",
    "if df is not None:\n",
    "    print(\"=== AN√ÅLISE DAS COLUNAS DE DATA ===\")\n",
    "\n",
    "    # Verificar formatos de data\n",
    "    date_columns = ['DTSTART', 'DTEND', 'DUE', 'CREATED']\n",
    "\n",
    "    for col in date_columns:\n",
    "        if col in df.columns:\n",
    "            print(f\"\\n{col}:\")\n",
    "            print(f\"  - Valores √∫nicos (sample): {df[col].dropna().unique()[:5]}\")\n",
    "            print(f\"  - Valores nulos: {df[col].isnull().sum()}\")\n",
    "            print(f\"  - Total n√£o-nulos: {df[col].notna().sum()}\")\n",
    "\n",
    "    # Verificar colunas categ√≥ricas importantes\n",
    "    print(f\"\\n=== COLUNAS CATEG√ìRICAS ===\")\n",
    "    categorical_cols = ['CALENDAR', 'CATEGORIES', 'PRIORITY']\n",
    "\n",
    "    for col in categorical_cols:\n",
    "        if col in df.columns:\n",
    "            print(f\"\\n{col}:\")\n",
    "            values = df[col].value_counts().head(10)\n",
    "            print(values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "86d9891c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== CONVERTENDO COLUNAS DE DATA ===\n",
      "Convertendo DTSTART...\n",
      "  - Convertidos: 7232\n",
      "  - Erros/Nulos: 0\n",
      "Convertendo DTEND...\n",
      "  - Convertidos: 7230\n",
      "  - Erros/Nulos: 2\n",
      "Convertendo CREATED...\n",
      "  - Convertidos: 7232\n",
      "  - Erros/Nulos: 0\n",
      "Convertendo DURATION...\n",
      "  - Convertidos: 7230\n",
      "  - Estat√≠sticas: min=0.08, max=435.00, m√©dia=3.20\n",
      "\n",
      "‚úÖ Convers√µes conclu√≠das!\n"
     ]
    }
   ],
   "source": [
    "# Converter colunas de data para datetime\n",
    "if df is not None:\n",
    "    print(\"=== CONVERTENDO COLUNAS DE DATA ===\")\n",
    "\n",
    "    # Fun√ß√£o para converter data de forma segura\n",
    "    def safe_datetime_convert(series, format_str='%d/%m/%Y %H:%M'):\n",
    "        try:\n",
    "            return pd.to_datetime(series, format=format_str, errors='coerce')\n",
    "        except:\n",
    "            return pd.to_datetime(series, errors='coerce')\n",
    "\n",
    "    # Converter colunas de data\n",
    "    date_columns = ['DTSTART', 'DTEND', 'CREATED']\n",
    "\n",
    "    for col in date_columns:\n",
    "        if col in df.columns:\n",
    "            print(f\"Convertendo {col}...\")\n",
    "            df[col] = safe_datetime_convert(df[col])\n",
    "            print(f\"  - Convertidos: {df[col].notna().sum()}\")\n",
    "            print(f\"  - Erros/Nulos: {df[col].isna().sum()}\")\n",
    "\n",
    "    # Converter DURATION para num√©rico\n",
    "    if 'DURATION' in df.columns:\n",
    "        print(\"Convertendo DURATION...\")\n",
    "        df['DURATION'] = pd.to_numeric(df['DURATION'], errors='coerce')\n",
    "        print(f\"  - Convertidos: {df['DURATION'].notna().sum()}\")\n",
    "        print(f\"  - Estat√≠sticas: min={df['DURATION'].min():.2f}, max={df['DURATION'].max():.2f}, m√©dia={df['DURATION'].mean():.2f}\")\n",
    "\n",
    "    print(\"\\n‚úÖ Convers√µes conclu√≠das!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdeae414",
   "metadata": {},
   "source": [
    "## COLUNA: SUMMARY"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f16a371f",
   "metadata": {},
   "source": [
    "### An√°lise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2cd70207",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== AN√ÅlISE DA COLUNA SUMMARY ===\n",
      "Quantidade de valores √∫nicos: 376\n",
      "Valores √∫nicos exportados para ../data/title_unique.csv\n"
     ]
    }
   ],
   "source": [
    "print(\"=== AN√ÅlISE DA COLUNA SUMMARY ===\")\n",
    "\n",
    "print(f\"Quantidade de valores √∫nicos: {df['SUMMARY'].nunique()}\")\n",
    "# print(f\"Valores √∫nicos: {df['SUMMARY'].unique()}\")\n",
    "\n",
    "# Exportar valores √∫nicos da coluna SUMMARY para uma tabela CSV e usar uma LLM para clusterizar informacoes parecidas\n",
    "unique_summary = df[['SUMMARY', 'CALENDAR']].drop_duplicates().rename(columns={'SUMMARY': 'TITLE'})\n",
    "unique_summary = unique_summary.sort_values(by='TITLE').reset_index(drop=True)\n",
    "unique_summary.to_csv('../data/title_calendar_unique.csv', index=False, encoding='utf-8')\n",
    "print(\"Valores √∫nicos exportados para ../data/title_unique.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2b76e0d",
   "metadata": {},
   "source": [
    "### Tratando valores da coluna SUMMARY que possuem dois valores na coluna CALENDAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f2b23e31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== TRATANDO Duplicatas da coluna SUMMARY ===\n",
      "Valores de CALENDAR para \"Academia\": ['Exerc√≠cios']\n",
      "Valores de CALENDAR para \"Aldeia\": ['Social']\n",
      "Valores de CALENDAR para \"Aula\": ['PUC']\n",
      "Valores de CALENDAR para \"BD: T2 G2\": ['Exames']\n",
      "Valores de CALENDAR para \"BIRUSAMBA DE VER√ÉO\": ['Social']\n",
      "Valores de CALENDAR para \"De-Para\": ['PUC']\n",
      "Valores de CALENDAR para \"Muay Thai\": ['Exerc√≠cios']\n",
      "Valores de CALENDAR para \"Psic√≥loga\": ['Sa√∫de']\n",
      "Valores de CALENDAR para \"SO: P1\": ['Exames']\n"
     ]
    }
   ],
   "source": [
    "# Coluna SUMMARY possui 30 valores que tem duas varia√ß√µes em 'CALENDAR'\n",
    "print(\"=== TRATANDO Duplicatas da coluna SUMMARY ===\")\n",
    "df['CALENDAR'] = df['CALENDAR'].replace('PUC üëª', 'PUC')\n",
    "\n",
    "# Corrigindo os valores duplicados de 'Academia'\n",
    "df.loc[(df['SUMMARY'] == 'Academia') & (df['CALENDAR'] == 'Pessoal'), 'CALENDAR'] = 'Exerc√≠cios' # 2\n",
    "print(f'Valores de CALENDAR para \"Academia\": {df.loc[df['SUMMARY'] == 'Academia', 'CALENDAR'].unique()}')\n",
    "\n",
    "# Corrigindo os valores duplicados de 'Aldeia'\n",
    "df.loc[(df['SUMMARY'] == 'Aldeia') & (df['CALENDAR'] == 'Pessoal'), 'CALENDAR'] = 'Social' # 2\n",
    "print(f'Valores de CALENDAR para \"Aldeia\": {df.loc[df['SUMMARY'] == 'Aldeia', 'CALENDAR'].unique()}')\n",
    "\n",
    "# Corrigindo os valores duplicados de 'Aula'\n",
    "df.loc[(df['SUMMARY'] == 'Aula') & (df['CALENDAR'] == 'Pessoal'), 'CALENDAR'] = 'PUC' # 2\n",
    "print(f'Valores de CALENDAR para \"Aula\": {df.loc[df['SUMMARY'] == 'Aula', 'CALENDAR'].unique()}')\n",
    "\n",
    "# Corrigindo os valores duplicados de 'BD: T2 G2'\n",
    "df.loc[(df['SUMMARY'] == 'BD: T2 G2') & (df['CALENDAR'] == 'PUC'), 'CALENDAR'] = 'Exames' # 2\n",
    "print(f'Valores de CALENDAR para \"BD: T2 G2\": {df.loc[df['SUMMARY'] == 'BD: T2 G2', 'CALENDAR'].unique()}')\n",
    "\n",
    "# Corrigindo os valores duplicados de 'BIRUSAMBA DE VER√ÉO'\n",
    "df.loc[(df['SUMMARY'] == 'BIRUSAMBA DE VER√ÉO'), 'CALENDAR'] = 'Social' # 2\n",
    "print(f'Valores de CALENDAR para \"BIRUSAMBA DE VER√ÉO\": {df.loc[df['SUMMARY'] == 'BIRUSAMBA DE VER√ÉO', 'CALENDAR'].unique()}')\n",
    "\n",
    "# Corrigindo os valores duplicados de De-Para\n",
    "df.loc[(df['SUMMARY'] == 'De-Para') & (df['CALENDAR'] == 'Exames'), 'CALENDAR'] = 'PUC' # 2\n",
    "print(f'Valores de CALENDAR para \"De-Para\": {df.loc[df[\"SUMMARY\"] == \"De-Para\", \"CALENDAR\"].unique()}')\n",
    "\n",
    "# Corrigindo os valores duplicados de 'Muay Thai'\n",
    "df.loc[(df['SUMMARY'] == 'Muay Thai') & (df['CALENDAR'] == 'Pessoal'), 'CALENDAR'] = 'Exerc√≠cios' # 2\n",
    "print(f'Valores de CALENDAR para \"Muay Thai\": {df.loc[df[\"SUMMARY\"] == \"Muay Thai\", \"CALENDAR\"].unique()}')\n",
    "\n",
    "# Corrigindo valores duplicados de 'Psic√≥loga'\n",
    "df.loc[(df['SUMMARY'] == 'Psic√≥loga') & (df['CALENDAR'] == 'Compromisso'), 'CALENDAR'] = 'Sa√∫de' # 2\n",
    "print(f'Valores de CALENDAR para \"Psic√≥loga\": {df.loc[df[\"SUMMARY\"] == \"Psic√≥loga\", \"CALENDAR\"].unique()}')\n",
    "\n",
    "# Corrigindo valores duplicados de 'SO: P1' # 2\n",
    "df.loc[(df['SUMMARY'] == 'SO: P1') & (df['CALENDAR'] == 'PUC'), 'CALENDAR'] = 'Exames' # 2\n",
    "print(f'Valores de CALENDAR para \"SO: P1\": {df.loc[df[\"SUMMARY\"] == \"SO: P1\", \"CALENDAR\"].unique()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2b8fc837",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== ENCONTRO DE DUPLICATAS DA COLUNA SUMMARY ===\n",
      "Quantidade de duplicatas encontradas: 4\n",
      "Duplicatas encontradas:\n",
      "         SUMMARY     CALENDAR\n",
      "2862  Alessandra  Compromisso\n",
      "3059  Alessandra        Sa√∫de\n",
      "4566    Itaipava      Pessoal\n",
      "5951    Itaipava       Social\n"
     ]
    }
   ],
   "source": [
    "print(\"=== ENCONTRO DE DUPLICATAS DA COLUNA SUMMARY ===\")\n",
    "duplicates = df[df.duplicated(subset='SUMMARY', keep=False)]\n",
    "# Seleciona duplicatas de SUMMARY que aparecem em mais de um CALENDAR\n",
    "duplicates_sum_cal = (\n",
    "    duplicates[['SUMMARY', 'CALENDAR']]\n",
    "    .drop_duplicates()\n",
    "    .groupby('SUMMARY')\n",
    "    .filter(lambda x: x['CALENDAR'].nunique() > 1)\n",
    "    .sort_values(by=['SUMMARY', 'CALENDAR'], ascending=[True, True])\n",
    ")\n",
    "print(f\"Quantidade de duplicatas encontradas: {duplicates_sum_cal.shape[0]}\")\n",
    "print(f\"Duplicatas encontradas:\\n{duplicates_sum_cal}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcf49091",
   "metadata": {},
   "source": [
    "### Entendendo os valores unicos da coluna CALENDAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "88647788",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== ENTENDENDO OS VALORES √öNICOS DA COLUNA CALENDAR ===\n",
      "Valores √∫nicos na coluna CALENDAR: ['Alimenta√ß√£o' 'PUC' 'Pessoal' 'Compromisso' 'Sa√∫de' 'Exames' 'Social'\n",
      " 'Games' 'Exerc√≠cios' 'RescueTime' 'Rotina' 'Trabalho' 'Viagens']\n",
      "\n",
      "Amostra de linhas com CALENDAR 'Rotina':\n",
      "['Deep Work']\n"
     ]
    }
   ],
   "source": [
    "print('=== ENTENDENDO OS VALORES √öNICOS DA COLUNA CALENDAR ===')\n",
    "print(f\"Valores √∫nicos na coluna CALENDAR: {df['CALENDAR'].unique()}\")\n",
    "\n",
    "# Amostra de linhas com valor 'Rotina'\n",
    "sample_rotina = df[df['CALENDAR'] == 'Rotina']['SUMMARY'].unique()\n",
    "print(f\"\\nAmostra de linhas com CALENDAR 'Rotina':\\n{sample_rotina}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47ababe5",
   "metadata": {},
   "source": [
    "# Exportar DataFrame completo para CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5a4b3e16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== SALVANDO DATASET PROCESSADO ===\n",
      "Colunas adicionadas: YEAR, MONTH, DAY_OF_WEEK, HOUR, DATE, DURATION_MINUTES\n",
      "‚úÖ Dataset processado salvo em: ../data/tasks_processed.csv\n",
      "\n",
      "=== ESTAT√çSTICAS FINAIS ===\n",
      "Total de registros: 7232\n",
      "Per√≠odo dos dados: 2002-04-22 00:00:00 at√© 2026-12-30 15:00:00\n",
      "Categorias √∫nicas: 13\n",
      "Dura√ß√£o m√©dia das tarefas: 192.2 minutos\n"
     ]
    }
   ],
   "source": [
    "# Salvar dataset processado\n",
    "if df is not None:\n",
    "    print(\"=== SALVANDO DATASET PROCESSADO ===\")\n",
    "\n",
    "    # Criar algumas colunas derivadas √∫teis\n",
    "    df['YEAR'] = df['DTSTART'].dt.year\n",
    "    df['MONTH'] = df['DTSTART'].dt.month\n",
    "    df['DAY_OF_WEEK'] = df['DTSTART'].dt.dayofweek  # 0=Monday, 6=Sunday\n",
    "    df['HOUR'] = df['DTSTART'].dt.hour\n",
    "    df['DATE'] = df['DTSTART'].dt.date\n",
    "\n",
    "    # Criar coluna de dura√ß√£o em minutos (se n√£o existe DURATION)\n",
    "    if 'DTSTART' in df.columns and 'DTEND' in df.columns:\n",
    "        df['DURATION_MINUTES'] = (df['DTEND'] - df['DTSTART']).dt.total_seconds() / 60\n",
    "\n",
    "    print(f\"Colunas adicionadas: YEAR, MONTH, DAY_OF_WEEK, HOUR, DATE, DURATION_MINUTES\")\n",
    "\n",
    "    # Salvar como CSV processado\n",
    "    output_path = '../data/tasks_processed.csv'\n",
    "    df.to_csv(output_path, index=False, encoding='utf-8')\n",
    "    print(f\"‚úÖ Dataset processado salvo em: {output_path}\")\n",
    "\n",
    "    # Estat√≠sticas finais\n",
    "    print(f\"\\n=== ESTAT√çSTICAS FINAIS ===\")\n",
    "    print(f\"Total de registros: {len(df)}\")\n",
    "    print(f\"Per√≠odo dos dados: {df['DTSTART'].min()} at√© {df['DTSTART'].max()}\")\n",
    "    print(f\"Categorias √∫nicas: {df['CALENDAR'].nunique()}\")\n",
    "    print(f\"Dura√ß√£o m√©dia das tarefas: {df['DURATION_MINUTES'].mean():.1f} minutos\")\n",
    "else:\n",
    "    print(\"‚ùå DataFrame n√£o dispon√≠vel para salvar.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
