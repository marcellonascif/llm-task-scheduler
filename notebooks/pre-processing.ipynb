{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "379d5361",
   "metadata": {},
   "source": [
    "# Pr√© processamento do dataset de tarefas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "29fcfc92",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8fed6f22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV carregado com engine C! 7232 linhas encontradas.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    df = pd.read_csv(\n",
    "        '../data/tasks.csv',\n",
    "        encoding='utf-8',\n",
    "        sep=\",\",\n",
    "        quotechar='\"',\n",
    "        on_bad_lines='skip',      # ignora linhas corrompidas\n",
    "        dtype=str,               # carrega tudo como string, depois ajusta\n",
    "        engine='c'          # usa engine python que √© mais tolerante\n",
    "    )\n",
    "    print(f\"CSV carregado com engine C! {len(df)} linhas encontradas.\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Erro ao ler CSV: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0a06b66e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== INFORMA√á√ïES B√ÅSICAS DO DATASET ===\n",
      "Shape: (7232, 17)\n",
      "\n",
      "Tipos de dados:\n",
      "SUMMARY                          object\n",
      "DTSTART                          object\n",
      "DTEND                            object\n",
      "DUE                              object\n",
      "NOTES                            object\n",
      "ATTENDEE                         object\n",
      "LOCATION                         object\n",
      "PRIORITY                         object\n",
      "URL                              object\n",
      "CALENDAR                         object\n",
      "UID                              object\n",
      "ORGANIZER                        object\n",
      "CATEGORIES                       object\n",
      "DURATION                         object\n",
      "REPLACES RECURRENT EVENT FROM    object\n",
      "CANCELLED                        object\n",
      "CREATED                          object\n",
      "dtype: object\n",
      "\n",
      "Primeiras 5 linhas:\n",
      "  SUMMARY           DTSTART             DTEND  DUE NOTES ATTENDEE LOCATION  \\\n",
      "0       üç≥  07/01/2025 08:00  07/01/2025 08:20  NaN   NaN      NaN      NaN   \n",
      "1       üßã  07/01/2025 10:00  07/01/2025 10:05  NaN   NaN      NaN      NaN   \n",
      "2      üçΩÔ∏è  07/01/2025 12:30  07/01/2025 13:00  NaN   NaN      NaN      NaN   \n",
      "3       ü•™  07/01/2025 16:00  07/01/2025 16:15  NaN   NaN      NaN      NaN   \n",
      "4       üçå  07/01/2025 18:00  07/01/2025 18:05  NaN   NaN      NaN      NaN   \n",
      "\n",
      "  PRIORITY  URL     CALENDAR  UID ORGANIZER CATEGORIES           DURATION  \\\n",
      "0      NaN  NaN  Alimenta√ß√£o  NaN       NaN        NaN   0.33333333333333   \n",
      "1      NaN  NaN  Alimenta√ß√£o  NaN       NaN        NaN  0.083333333333333   \n",
      "2      NaN  NaN  Alimenta√ß√£o  NaN       NaN        NaN                0.5   \n",
      "3      NaN  NaN  Alimenta√ß√£o  NaN       NaN        NaN               0.25   \n",
      "4      NaN  NaN  Alimenta√ß√£o  NaN       NaN        NaN  0.083333333333333   \n",
      "\n",
      "  REPLACES RECURRENT EVENT FROM CANCELLED           CREATED  \n",
      "0                           NaN       NaN  07/01/2025 10:12  \n",
      "1                           NaN       NaN  07/01/2025 10:14  \n",
      "2                           NaN       NaN  07/01/2025 10:15  \n",
      "3                           NaN       NaN  07/01/2025 10:16  \n",
      "4                           NaN       NaN  07/01/2025 10:17  \n",
      "\n",
      "Valores nulos por coluna:\n",
      "SUMMARY                             0\n",
      "DTSTART                             0\n",
      "DTEND                               2\n",
      "DUE                              7232\n",
      "NOTES                            6657\n",
      "ATTENDEE                         7193\n",
      "LOCATION                         5457\n",
      "PRIORITY                         7232\n",
      "URL                              7232\n",
      "CALENDAR                            0\n",
      "UID                              7232\n",
      "ORGANIZER                        7204\n",
      "CATEGORIES                       7232\n",
      "DURATION                            2\n",
      "REPLACES RECURRENT EVENT FROM    7145\n",
      "CANCELLED                        7047\n",
      "CREATED                             0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Verificar informa√ß√µes b√°sicas do dataset\n",
    "if df is not None:\n",
    "    print(\"=== INFORMA√á√ïES B√ÅSICAS DO DATASET ===\")\n",
    "    print(f\"Shape: {df.shape}\")\n",
    "    print(f\"\\nTipos de dados:\")\n",
    "    print(df.dtypes)\n",
    "    print(f\"\\nPrimeiras 5 linhas:\")\n",
    "    print(df.head())\n",
    "    print(f\"\\nValores nulos por coluna:\")\n",
    "    print(df.isnull().sum())\n",
    "else:\n",
    "    print(\"DataFrame n√£o foi carregado corretamente.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "541c8837",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== AN√ÅLISE DAS COLUNAS DE DATA ===\n",
      "\n",
      "DTSTART:\n",
      "  - Valores √∫nicos (sample): ['07/01/2025 08:00' '07/01/2025 10:00' '07/01/2025 12:30'\n",
      " '07/01/2025 16:00' '07/01/2025 18:00']\n",
      "  - Valores nulos: 0\n",
      "  - Total n√£o-nulos: 7232\n",
      "\n",
      "DTEND:\n",
      "  - Valores √∫nicos (sample): ['07/01/2025 08:20' '07/01/2025 10:05' '07/01/2025 13:00'\n",
      " '07/01/2025 16:15' '07/01/2025 18:05']\n",
      "  - Valores nulos: 2\n",
      "  - Total n√£o-nulos: 7230\n",
      "\n",
      "DUE:\n",
      "  - Valores √∫nicos (sample): []\n",
      "  - Valores nulos: 7232\n",
      "  - Total n√£o-nulos: 0\n",
      "\n",
      "CREATED:\n",
      "  - Valores √∫nicos (sample): ['07/01/2025 10:12' '07/01/2025 10:14' '07/01/2025 10:15'\n",
      " '07/01/2025 10:16' '07/01/2025 10:17']\n",
      "  - Valores nulos: 0\n",
      "  - Total n√£o-nulos: 7232\n",
      "\n",
      "=== COLUNAS CATEG√ìRICAS ===\n",
      "\n",
      "CALENDAR:\n",
      "CALENDAR\n",
      "Alimenta√ß√£o    2323\n",
      "Trabalho       1255\n",
      "PUC            1219\n",
      "Exerc√≠cios      870\n",
      "Pessoal         564\n",
      "PUC üëª           514\n",
      "Sa√∫de           171\n",
      "Exames          117\n",
      "Social           52\n",
      "Compromisso      49\n",
      "Name: count, dtype: int64\n",
      "\n",
      "CATEGORIES:\n",
      "Series([], Name: count, dtype: int64)\n",
      "\n",
      "PRIORITY:\n",
      "Series([], Name: count, dtype: int64)\n"
     ]
    }
   ],
   "source": [
    "# Analisar as colunas de data especificamente\n",
    "if df is not None:\n",
    "    print(\"=== AN√ÅLISE DAS COLUNAS DE DATA ===\")\n",
    "\n",
    "    # Verificar formatos de data\n",
    "    date_columns = ['DTSTART', 'DTEND', 'DUE', 'CREATED']\n",
    "\n",
    "    for col in date_columns:\n",
    "        if col in df.columns:\n",
    "            print(f\"\\n{col}:\")\n",
    "            print(f\"  - Valores √∫nicos (sample): {df[col].dropna().unique()[:5]}\")\n",
    "            print(f\"  - Valores nulos: {df[col].isnull().sum()}\")\n",
    "            print(f\"  - Total n√£o-nulos: {df[col].notna().sum()}\")\n",
    "\n",
    "    # Verificar colunas categ√≥ricas importantes\n",
    "    print(f\"\\n=== COLUNAS CATEG√ìRICAS ===\")\n",
    "    categorical_cols = ['CALENDAR', 'CATEGORIES', 'PRIORITY']\n",
    "\n",
    "    for col in categorical_cols:\n",
    "        if col in df.columns:\n",
    "            print(f\"\\n{col}:\")\n",
    "            values = df[col].value_counts().head(10)\n",
    "            print(values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "86d9891c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== CONVERTENDO COLUNAS DE DATA ===\n",
      "Convertendo DTSTART...\n",
      "  - Convertidos: 7232\n",
      "  - Erros/Nulos: 0\n",
      "Convertendo DTEND...\n",
      "  - Convertidos: 7230\n",
      "  - Erros/Nulos: 2\n",
      "Convertendo CREATED...\n",
      "  - Convertidos: 7232\n",
      "  - Erros/Nulos: 0\n",
      "Convertendo DURATION...\n",
      "  - Convertidos: 7230\n",
      "  - Estat√≠sticas: min=0.08, max=435.00, m√©dia=3.20\n",
      "\n",
      "‚úÖ Convers√µes conclu√≠das!\n"
     ]
    }
   ],
   "source": [
    "# Converter colunas de data para datetime\n",
    "if df is not None:\n",
    "    print(\"=== CONVERTENDO COLUNAS DE DATA ===\")\n",
    "\n",
    "    # Fun√ß√£o para converter data de forma segura\n",
    "    def safe_datetime_convert(series, format_str='%d/%m/%Y %H:%M'):\n",
    "        try:\n",
    "            return pd.to_datetime(series, format=format_str, errors='coerce')\n",
    "        except:\n",
    "            return pd.to_datetime(series, errors='coerce')\n",
    "\n",
    "    # Converter colunas de data\n",
    "    date_columns = ['DTSTART', 'DTEND', 'CREATED']\n",
    "\n",
    "    for col in date_columns:\n",
    "        if col in df.columns:\n",
    "            print(f\"Convertendo {col}...\")\n",
    "            df[col] = safe_datetime_convert(df[col])\n",
    "            print(f\"  - Convertidos: {df[col].notna().sum()}\")\n",
    "            print(f\"  - Erros/Nulos: {df[col].isna().sum()}\")\n",
    "\n",
    "    # Converter DURATION para num√©rico\n",
    "    if 'DURATION' in df.columns:\n",
    "        print(\"Convertendo DURATION...\")\n",
    "        df['DURATION'] = pd.to_numeric(df['DURATION'], errors='coerce')\n",
    "        print(f\"  - Convertidos: {df['DURATION'].notna().sum()}\")\n",
    "        print(f\"  - Estat√≠sticas: min={df['DURATION'].min():.2f}, max={df['DURATION'].max():.2f}, m√©dia={df['DURATION'].mean():.2f}\")\n",
    "\n",
    "    print(\"\\n‚úÖ Convers√µes conclu√≠das!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdeae414",
   "metadata": {},
   "source": [
    "### COLUNA: SUMMARY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cd70207",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== AN√ÅlISE DA COLUNA SUMMARY ===\n",
      "Quantidade de valores √∫nicos: 376\n",
      "Valores √∫nicos: ['üç≥' 'üßã' 'üçΩÔ∏è' 'ü•™' 'üçå' 'INF1410 - Gerenc Proj Inf'\n",
      " 'INF1608 - An√°lise Num√©rica' 'ADM1019 - Intr. Finan√ßas'\n",
      " 'INF1629 - P. Eng. de Software' 'Parab√©ns!' 'Alessandra' 'RM' 'P3'\n",
      " 'Psic√≥loga' 'Zion' 'ZION' 'Autoescola' 'Aula de Viol√£o' 'Cortar cabelo'\n",
      " 'Aula de M√∫sica' 'Centro' 'Conversa PUC' 'Auto Escola: Prova Pr√°tica'\n",
      " 'Detran' 'üé§ Aula de Canto' 'üé∏ Aula de Guitarra' 'Gradua√ß√£o Muay Thai'\n",
      " 'Visita Rede' 'Mago da M√∫sica link' 'Conversa Pedro' 'T2 √Ålgebra'\n",
      " 'Prova Auto Escola' 'INF1301 - Relat√≥rio Plano de A√ß√£o' 'P1 INF1018'\n",
      " 'P1 ProgMod' 'Entrega Trabalho INF1018' 'T3 √Ålgebra' 'T4 √Ålgebra'\n",
      " 'P2 INF1018' 'P2 √Ålgebra' 'Trab INF1018' 'P3 √Ålgebra' 'P2 ProgMod'\n",
      " 'Avalia√ß√£o 1 √Ålgebra' 'P1 C√°lculo' 'T1 Maple √Ålgebra'\n",
      " 'Avalia√ß√£o 2 √Ålgebra' 'P1 √Ålgebra' 'Teste 1 ProbComp' 'Av. Lab1 C√°lculo'\n",
      " 'Trabalho 2 IAC' 'Trabalho 3 IAC' 'Trab G1 ProbComp' 'Teste 2 ProbComp'\n",
      " 'Avalia√ß√£o 3 √Ålgebra' 'P1 IAC' 'Avalia√ß√£o 4 √Ålgebra'\n",
      " 'Tete 2 Maple √Ålgebra' 'Semana 6' 'Semana 7' 'Semana 8'\n",
      " 'Atividade 2 C√°lculo' 'Semana 10' 'Semana 9' 'Semana 11' 'P2 C√°lculo'\n",
      " 'Av. Lab2 C√°lculo' 'Av Extra √Ålgebra' 'Av Extra C √Ålgebra'\n",
      " 'Av Extra D √Ålgebra' 'Avalia√ßao 5 √Ålgebra' 'Trabalho 4 IAC'\n",
      " 'Av 6 √Ålgebra' 'P2 IAC' 'Teste e Medi√ß√£o: Atividade 1' 'SO: Lab 2'\n",
      " 'Atividade Teste' 'POO: P1' 'Teste e Med√ß√£o: P1' 'POO: Trab I' 'BD: T2'\n",
      " 'SO: P1' 'BD: Trab 1' 'POO: Trab II' 'SO: Trab 1' 'BD: T3' 'SO: Lab 5'\n",
      " 'POO: Trab III' 'BD: T1 G2' 'POO: Trab IV' 'TMS: Atividade 3' 'SO: Lab 6'\n",
      " 'TMS: P2' 'BD: Trab 2' 'POO: Apresenta√ß√£o' 'BD: T2 G2' 'SO: P2'\n",
      " 'IHC: Trab II' 'SO: Trab 2' 'IHC: Apresenta√ß√£o' 'De-Para'\n",
      " 'De/Para Alternativo' 'CD - Apresenta√ß√£o' 'PCS: Apresenta√ß√£o' 'Redes: P1'\n",
      " 'ED: P1' 'PCS: Apresenta√ß√£o G2' 'Redes: Trab 1' 'CD: Apresenta√ß√£o G2'\n",
      " 'Redes: P2' 'ED: P2' 'ED: Lista 4' 'P2 - EDA' 'Apresenta√ß√£o T2 - EDA'\n",
      " 'PF - EDA' 'PSR: MP1' 'AA: P1' 'ALS - P1' 'ProbComp - T1' 'AA: P2'\n",
      " 'Trabalho 2 AA' 'ProbComp - T2' 'ALS - P2' 'AA: P3'\n",
      " 'Apresenta√ß√£o EST√ÅGIO' 'Trabalho 3 AA' 'ProbComp - P2' 'Trabalho ALS'\n",
      " 'Projeto Final PSR' 'BIRUSAMBA DE VER√ÉO' 'T2 C√°lculo' 'P3 C√°lculo'\n",
      " 'Dr Bruno' 'Quiropraxia' 'Exame de Imagem' 'Cirurgi√£o' 'Ortopedista'\n",
      " 'Dermatologista' 'Exame de Sangue' 'Endoscopia' 'Psiquiatra' 'Dentista'\n",
      " 'Exames de Imagem' 'Bioimped√¢ncia' 'Oftalmologista' 'LIVRE'\n",
      " 'Viviane Nutri' 'Dra. V√¢nia' 'Psic√≥logo' 'Pilates' 'Nutricionista'\n",
      " 'Hogwarts Legacy' 'Minecraft: Legends' 'Diablo IV' 'GMTK GameJam'\n",
      " 'Academia' 'Futev√¥lei' 'Academia Ideal' 'Muay Thai' 'Basquete PUC'\n",
      " 'Spinning' 'Aula da Liane' 'Casa do Felipe' 'Anivers√°rio da minha irm√£'\n",
      " 'Anivers√°rio da minha m√£e' 'Ps Plus' 'Meu Anivers√°rio'\n",
      " 'Anivers√°rio do meu pai' 'Lembrar Marie' 'Formatura CSA' 'Help!' 'Aula'\n",
      " 'Baile da Gaiola' 'Amaz√¥nia' 'Anivers√°rio de Namoro'\n",
      " 'Estudar c√°lculo e ficha 2' 'SEASON NOVA RL' 'BLACK FRIDAY'\n",
      " 'FaceTime Alessandra' 'Estudo' 'Arrumar' 'Acordar' 'Barra Shopping'\n",
      " '[Nubank] Vencimento da Fatura de Mar√ßo' 'Almo√ßo' 'Feriado' 'Itaipava'\n",
      " 'Niver' 'FOCO' 'Primo rico' 'DEVOLU√á√ÉO ZARA'\n",
      " 'Reuni√£o de cronograma do AcessoRio' 'Corte Masculino'\n",
      " 'Grava√ß√£o Comunica√ß√£o InterCriar'\n",
      " 'Oportunidade Guelt | Felipe Khouri Gameleira' 'WWDC-SS Crash Challenge'\n",
      " 'üåô' 'Aldeia' 'Call Checkpoint AcessoRio' 'Aldeia S√°bado [FERIADO]'\n",
      " 'Aldeia S√°bado' 'Grava√ß√£o AcessoRio' 'Fone' 'QuadCast'\n",
      " 'GMKT Jam - Entrega' 'Reuni√£o com OutSystems' 'WWDC Teaching - Kick Off'\n",
      " 'WWDC Teaching - First Steps' 'Avalia√ß√£o imobili√°ria' 'WWDC iLearning'\n",
      " 'Mentoria Inversu (Felipe Gameleira)' 'üòé Decompress'\n",
      " 'Mentoria Inversu - Felipe Gameleira' 'Reservation at Yusha'\n",
      " 'Entrevista Est√°gio: Felipe' 'Entrevista Est√°gio Desenvolvedor: Felipe'\n",
      " 'Estudar C√°lculo' 'AI Salon Rio de Janeiro' 'IA &'\n",
      " 'AI Salon Rio de Janeiro #4' 'Morgan Jay' 'Ajuste de matr√≠cula'\n",
      " 'Ajuste de Matr√≠cula II' 'MAT1162 - C√ÅLCULO A V√ÅRIAS VARI√ÅVEIS I'\n",
      " 'Volta √†s aulas' 'INF1301 - PROGRAMA√á√ÉO MODULAR'\n",
      " 'INF1018 - SOFTWARE B√ÅSICO' 'MAT1260 - √ÅLGEBRA LINEAR 1' 'DE PARA'\n",
      " 'T1 √Ålgebra' 'INF1018 - MONITORIA' 'Simulador de Matr√≠cula'\n",
      " 'Matr√≠cula PUC' 'Ajuste de Matr√≠cula'\n",
      " 'INF1636 - Programa√ß√£o Orientada √† Objetos'\n",
      " 'INF1027 - Teste e Medi√ß√£o de Software' 'INF1383 - Bancos de Dados'\n",
      " 'INF1316 - SO' 'INF1403 - IHC' 'De/Para Regimental' 'SO: Lab 1'\n",
      " 'Ferias PUC' 'Volta √†s Aulas' 'INF1032 - Ci√™ncia de Dados'\n",
      " 'INF1022 - Analisadores L√©x. e Sint.' 'INF1640 - Redes de Computadores'\n",
      " 'INF1631 - Estruturas Discretas' 'CRE1141 - √âtica Crist√£'\n",
      " 'INF1028 - Projeto e Constru√ß√£o de Sistemas' 'INF1307 - Games'\n",
      " 'INF1022 - ALS' 'INF1771 - IA' 'INF2471 - Prob Comp' 'INF1010 - EDA'\n",
      " 'INF1338 - LLM' 'INF1721 - AA' 'INF1036 - Prob Comp'\n",
      " 'INF1350 - Prog Sis Reat' 'INF1920 - Aula Expositiva'\n",
      " 'Conversa TCC Felipe Gameleira' 'MAT4162 - C√°lculo II'\n",
      " 'INF1314 - Startup IA' 'Reuni√£o TCC' 'Teste C√°lculo II' 'Devs no Pilotis'\n",
      " '‚è± 1:51' '‚è± 6:35' '‚è± 7:12' '‚è± 0:57' '‚è± 1:14' '‚è± 3:33' '‚è± 6:55' '‚è± 4:30'\n",
      " '‚è± 6:31' '‚è± 7:45' '‚è± 6:23' '‚è± 9:05 üóì 0:18' '‚è± 4:51' '‚è± 3:09' '‚è± 5:47'\n",
      " '‚è± 4:27' '‚è± 5:03' '‚è± 2:01' '‚è± 5:49' '‚è± 3:27' '‚è± 8:02' '‚è± 6:01' '‚è± 8:22'\n",
      " '‚è± 12:34' '‚è± 7:02 üóì 0:14' '‚è± 7:05 üóì 0:36' '‚è± 3:56' '‚è± 4:18' '‚è± 8:31'\n",
      " '‚è± 6:15' '‚è± 4:50' '‚è± 7:44' '‚è± 7:51 üóì 0:15' '‚è± 3:24' '‚è± 2:31' '‚è± 1:44'\n",
      " '‚è± 3:11' '‚è± 0:32' '‚è± 0:03' '‚è± 2:13' '‚è± 3:38' '‚è± 2:41' '‚è± 3:08' '‚è± 1:48'\n",
      " 'Deep Work' 'Ingresso Harry' 'Niver Gabi' 'Nover Sofia K' 'Thor'\n",
      " 'The Avengers' 'Rafael Portugal' 'Niver Giovanna Lopes' 'Churrascl√©rigos'\n",
      " 'Almo√ßo V√≥' 'Santa Sexta' 'Niver Gi Fortes' 'Casamento' 'Rock In Rio'\n",
      " 'Niver Amanda' 'Niver Luana Maia' 'Niver Lara' 'Niver M√£e'\n",
      " 'Ballet Marina' 'HARRY STYLES - LOVE ON TOUR - RIO DE JANEIRO'\n",
      " 'Pulo Big Jump' 'Resenha Felipe' 'Niver Isabella' 'Festa Niver'\n",
      " 'Niver Felipe' 'Niver Laura' 'Niver Aninha' 'Niver Rapha' 'Prime Day'\n",
      " 'Niver Julia' 'Niver Carol Benchimol' 'Festa Duda Castro'\n",
      " 'Churras Marcos' 'Festa Re' 'Viagem Secret√°rio' 'Os Barbixas'\n",
      " 'RPG Goulart' 'Churras Caio' 'Niver Millena' 'Niver Lu' 'Niver Caroli'\n",
      " 'Niver Be' 'Formatura Renata' 'Niver Lucca' 'Niver Caio' 'Churras Z√©'\n",
      " 'Formatura Lu' 'Apple Developer Academy' 'Animate Ideas with Keynote'\n",
      " 'Programar Cena' 'LAB' 'Apple' 'Academy' 'WWDC' 'Reuni√£o Nick + Tio'\n",
      " 'Churrasco Academy' 'Trabalho I9' 'I9 Cultura' 'Reuni√£o Prog ATLAS'\n",
      " 'ECOA' 'Conversa Bruno' 'Reuni√£o Play Time - Goulart' 'Reuni√£o Play Time'\n",
      " 'M3' 'Petr√≥polis' 'Petr√≥polis Torres' 'Petr√≥polis Juliana']\n",
      "Valores √∫nicos exportados para ../data/title_unique.csv\n",
      "Valores √∫nicos exportados para ../data/summary_unique.csv\n"
     ]
    }
   ],
   "source": [
    "print(\"=== AN√ÅlISE DA COLUNA SUMMARY ===\")\n",
    "\n",
    "print(f\"Quantidade de valores √∫nicos: {df['SUMMARY'].nunique()}\")\n",
    "print(f\"Valores √∫nicos: {df['SUMMARY'].unique()}\")\n",
    "\n",
    "# Exportar valores √∫nicos da coluna SUMMARY para uma tabela CSV e usar uma LLM para clusterizar informacoes parecidas\n",
    "unique_summary = pd.DataFrame({'TITLE': df['SUMMARY'].unique()})\n",
    "unique_summary.to_csv('../data/title_unique.csv', index=False, encoding='utf-8')\n",
    "print(\"Valores √∫nicos exportados para ../data/title_unique.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5a4b3e16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== SALVANDO DATASET PROCESSADO ===\n",
      "Colunas adicionadas: YEAR, MONTH, DAY_OF_WEEK, HOUR, DATE, DURATION_MINUTES\n",
      "‚úÖ Dataset processado salvo em: ../data/tasks_processed.csv\n",
      "\n",
      "=== ESTAT√çSTICAS FINAIS ===\n",
      "Total de registros: 7232\n",
      "Per√≠odo dos dados: 2002-04-22 00:00:00 at√© 2026-12-30 15:00:00\n",
      "Categorias √∫nicas: 14\n",
      "Dura√ß√£o m√©dia das tarefas: 192.2 minutos\n"
     ]
    }
   ],
   "source": [
    "# Salvar dataset processado\n",
    "if df is not None:\n",
    "    print(\"=== SALVANDO DATASET PROCESSADO ===\")\n",
    "\n",
    "    # Criar algumas colunas derivadas √∫teis\n",
    "    df['YEAR'] = df['DTSTART'].dt.year\n",
    "    df['MONTH'] = df['DTSTART'].dt.month\n",
    "    df['DAY_OF_WEEK'] = df['DTSTART'].dt.dayofweek  # 0=Monday, 6=Sunday\n",
    "    df['HOUR'] = df['DTSTART'].dt.hour\n",
    "    df['DATE'] = df['DTSTART'].dt.date\n",
    "\n",
    "    # Criar coluna de dura√ß√£o em minutos (se n√£o existe DURATION)\n",
    "    if 'DTSTART' in df.columns and 'DTEND' in df.columns:\n",
    "        df['DURATION_MINUTES'] = (df['DTEND'] - df['DTSTART']).dt.total_seconds() / 60\n",
    "\n",
    "    print(f\"Colunas adicionadas: YEAR, MONTH, DAY_OF_WEEK, HOUR, DATE, DURATION_MINUTES\")\n",
    "\n",
    "    # Salvar como CSV processado\n",
    "    output_path = '../data/tasks_processed.csv'\n",
    "    df.to_csv(output_path, index=False, encoding='utf-8')\n",
    "    print(f\"‚úÖ Dataset processado salvo em: {output_path}\")\n",
    "\n",
    "    # Estat√≠sticas finais\n",
    "    print(f\"\\n=== ESTAT√çSTICAS FINAIS ===\")\n",
    "    print(f\"Total de registros: {len(df)}\")\n",
    "    print(f\"Per√≠odo dos dados: {df['DTSTART'].min()} at√© {df['DTSTART'].max()}\")\n",
    "    print(f\"Categorias √∫nicas: {df['CALENDAR'].nunique()}\")\n",
    "    print(f\"Dura√ß√£o m√©dia das tarefas: {df['DURATION_MINUTES'].mean():.1f} minutos\")\n",
    "else:\n",
    "    print(\"‚ùå DataFrame n√£o dispon√≠vel para salvar.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
