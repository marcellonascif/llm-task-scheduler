{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "379d5361",
   "metadata": {},
   "source": [
    "# Pr√© processamento da coluna SUMMARY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "29fcfc92",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import unicodedata\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fed6f22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV carregado com engine C! 4463 linhas encontradas.\n",
      "‚úÖ Colunas de data convertidas para datetime\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    df = pd.read_csv(\n",
    "        '../data/new_tasks.csv',\n",
    "        encoding='utf-8',\n",
    "        sep=\",\",\n",
    "    )\n",
    "    print(f\"CSV carregado com engine C! {len(df)} linhas encontradas.\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Erro ao ler CSV: {e}\")\n",
    "\n",
    "# Converter colunas de data para datetime\n",
    "df['DTSTART'] = pd.to_datetime(df['DTSTART'])\n",
    "df['DTEND'] = pd.to_datetime(df['DTEND'])\n",
    "df['CREATED'] = pd.to_datetime(df['CREATED'])\n",
    "print(\"Colunas de data convertidas para datetime\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "0a06b66e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== INFORMA√á√ïES B√ÅSICAS DO DATASET ===\n",
      "Shape: (4463, 6)\n",
      "Colunas: ['SUMMARY', 'DTSTART', 'DTEND', 'CALENDAR', 'DURATION', 'CREATED']\n",
      "Tipos de dados:\n",
      "SUMMARY             object\n",
      "DTSTART     datetime64[ns]\n",
      "DTEND       datetime64[ns]\n",
      "CALENDAR            object\n",
      "DURATION           float64\n",
      "CREATED     datetime64[ns]\n",
      "dtype: object\n",
      "\n",
      "Resumo da coluna SUMMARY:\n",
      "  - Tipo de dado: object\n",
      "  - Valores √∫nicos: 372\n",
      "  - Valores nulos: 0\n",
      "  - Primeiros 5 valores:\n",
      "0     üç≥\n",
      "1     üßã\n",
      "2    üçΩÔ∏è\n",
      "3     ü•™\n",
      "4     üçå\n",
      "Name: SUMMARY, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Verificar informa√ß√µes b√°sicas do dataset\n",
    "print(\"=== INFORMA√á√ïES B√ÅSICAS DO DATASET ===\")\n",
    "print(f\"Shape: {df.shape}\")\n",
    "print(f\"Colunas: {df.columns.tolist()}\")\n",
    "print(f\"Tipos de dados:\\n{df.dtypes}\")\n",
    "\n",
    "# Informa√ß√µes apenas da coluna SUMMARY\n",
    "print(f\"\\nResumo da coluna SUMMARY:\")\n",
    "print(f\"  - Tipo de dado: {df['SUMMARY'].dtype}\")\n",
    "print(f\"  - Valores √∫nicos: {df['SUMMARY'].nunique()}\")\n",
    "print(f\"  - Valores nulos: {df['SUMMARY'].isnull().sum()}\")\n",
    "print(f\"  - Primeiros 5 valores:\\n{df['SUMMARY'].head()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f16a371f",
   "metadata": {},
   "source": [
    "### An√°lise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "2cd70207",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== AN√ÅlISE DA COLUNA SUMMARY ===\n",
      "Quantidade de valores √∫nicos: 372\n"
     ]
    }
   ],
   "source": [
    "print(\"=== AN√ÅlISE DA COLUNA SUMMARY ===\")\n",
    "\n",
    "print(f\"Quantidade de valores √∫nicos: {df['SUMMARY'].nunique()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03bbf7f2",
   "metadata": {},
   "source": [
    "### Corrigindo os valores que est√£o com EMOJI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "c1aa3804",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     üç≥\n",
      "1     üßã\n",
      "2    üçΩÔ∏è\n",
      "3     ü•™\n",
      "4     üçå\n",
      "5    üçΩÔ∏è\n",
      "6     üç≥\n",
      "7     üßã\n",
      "Name: SUMMARY, dtype: object\n",
      "0      cafe da manha\n",
      "1    lanche da manha\n",
      "2             almoco\n",
      "3    lanche da tarde\n",
      "4         pre-treino\n",
      "5             jantar\n",
      "6      cafe da manha\n",
      "7    lanche da manha\n",
      "Name: SUMMARY, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(df['SUMMARY'].head(8))\n",
    "\n",
    "# üßã: lanche da manha\n",
    "# üçΩÔ∏è e antes das 18:00: almoco\n",
    "# ü•™: lanche da tarde\n",
    "# üçå: pre-treino\n",
    "# üçΩÔ∏è e exatamente ou depois das 18:00: jantar\n",
    "\n",
    "df.loc[df['SUMMARY'] == 'üç≥', 'SUMMARY'] = 'cafe da manha'\n",
    "df.loc[df['SUMMARY'] == 'üßã', 'SUMMARY'] = 'lanche da manha'\n",
    "# Almo√ßo: emoji üçΩÔ∏è e come√ßa antes das 18h\n",
    "df.loc[(df['SUMMARY'] == 'üçΩÔ∏è') & (pd.to_datetime(df['DTSTART']).dt.hour < 18), 'SUMMARY'] = 'almoco'\n",
    "df.loc[df['SUMMARY'] == 'ü•™', 'SUMMARY'] = 'lanche da tarde'\n",
    "df.loc[df['SUMMARY'] == 'üçå', 'SUMMARY'] = 'pre-treino'\n",
    "df.loc[(df['SUMMARY'] == 'üçΩÔ∏è') & (pd.to_datetime(df['DTSTART']).dt.hour >= 18), 'SUMMARY'] = 'jantar'\n",
    "\n",
    "print(df['SUMMARY'].head(8))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dbda371",
   "metadata": {},
   "source": [
    "## Limpando"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "3ddcfa37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Avalia√ß√£o da coluna SUMMARY antes da normaliza√ß√£o ===\n",
      "Valores √∫nicos: 373\n",
      "Exemplos aleat√≥rios: ['Pulo Big Jump', 'INF1301 - Relat√≥rio Plano de A√ß√£o', 'Zion', 'Niver Giovanna Lopes', 'Avalia√ß√£o 4 √Ålgebra']\n",
      "\n",
      "=== Avalia√ß√£o da coluna SUMMARY depois da normaliza√ß√£o ===\n",
      "Valores √∫nicos: 369\n",
      "Exemplos aleat√≥rios: ['festa niver', 'p1 inf1018', 'zion', 'formatura renata', 'tete 2 maple algebra']\n"
     ]
    }
   ],
   "source": [
    "def normalize_text(text):\n",
    "    if pd.isnull(text):\n",
    "        return \"\"\n",
    "    # Lowercase\n",
    "    text = text.lower()\n",
    "    # Remove accents\n",
    "    text = unicodedata.normalize('NFKD', text).encode('ASCII', 'ignore').decode('utf-8')\n",
    "    # Remove extra spaces\n",
    "    text = ' '.join(text.split())\n",
    "    return text\n",
    "\n",
    "# Avalia√ß√£o antes da normaliza√ß√£o\n",
    "print(\"=== Avalia√ß√£o da coluna SUMMARY antes da normaliza√ß√£o ===\")\n",
    "print(f\"Valores √∫nicos: {df['SUMMARY'].nunique()}\")\n",
    "print(f\"Exemplos aleat√≥rios: {df['SUMMARY'].drop_duplicates().sample(5, random_state=42).tolist()}\")\n",
    "\n",
    "df['SUMMARY'] = df['SUMMARY'].apply(normalize_text)\n",
    "\n",
    "# Avalia√ß√£o depois da normaliza√ß√£o\n",
    "print(\"\\n=== Avalia√ß√£o da coluna SUMMARY depois da normaliza√ß√£o ===\")\n",
    "print(f\"Valores √∫nicos: {df['SUMMARY'].nunique()}\")\n",
    "print(f\"Exemplos aleat√≥rios: {df['SUMMARY'].drop_duplicates().sample(5, random_state=42).tolist()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6e8396b",
   "metadata": {},
   "source": [
    "### Dropando valores que n√£o s√£o necess√°rios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "7afa404f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numero de linhas antes de retirar RescueTime: 4463\n",
      "Numero de linhas depois de retirar RescueTime: 4418\n"
     ]
    }
   ],
   "source": [
    "print('Numero de linhas antes de retirar RescueTime:', len(df))\n",
    "df = df[df['CALENDAR'] != 'RescueTime']\n",
    "print('Numero de linhas depois de retirar RescueTime:', len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "88ade517",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N√∫mero de linhas antes de retirar o Rotina:  4418\n",
      "N√∫mero de linhas depois de retirar o Rotina:  4372\n"
     ]
    }
   ],
   "source": [
    "print('N√∫mero de linhas antes de retirar o Rotina: ', len(df))\n",
    "df = df[df['CALENDAR'] != 'Rotina']\n",
    "print('N√∫mero de linhas depois de retirar o Rotina: ', len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "2210e6fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N√∫mero de linhas antes de retirar parabens!:  4372\n",
      "N√∫mero de linhas depois de retirar parabens!:  4372\n"
     ]
    }
   ],
   "source": [
    "print('N√∫mero de linhas antes de retirar parabens!: ', len(df))\n",
    "df = df[df['SUMMARY'] != 'parabens']\n",
    "print('N√∫mero de linhas depois de retirar parabens!: ', len(df))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2b76e0d",
   "metadata": {},
   "source": [
    "### Tratando valores da coluna SUMMARY que possuem dois valores na coluna CALENDAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "f2b23e31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== TRATANDO Duplicatas da coluna SUMMARY ===\n",
      "Valores de CALENDAR para \"Academia\": ['Exerc√≠cios']\n",
      "Valores de CALENDAR para \"Aldeia\": ['Social']\n",
      "Valores de CALENDAR para \"Alessandra\": ['Sa√∫de']\n",
      "Valores de CALENDAR para \"Aula\": ['PUC']\n",
      "Valores de CALENDAR para \"BD: T2 G2\": ['Exames']\n",
      "Valores de CALENDAR para \"BIRUSAMBA DE VER√ÉO\": ['Social']\n",
      "Valores de CALENDAR para \"De-Para\": ['PUC']\n",
      "Valores de CALENDAR para \"Muay Thai\": ['Exerc√≠cios']\n",
      "Valores de CALENDAR para \"Psic√≥loga\": ['Sa√∫de']\n",
      "Valores de CALENDAR para \"SO: P1\": ['Exames']\n",
      "Valores de CALENDAR para \"Itaipava\": ['Social']\n"
     ]
    }
   ],
   "source": [
    "# Coluna SUMMARY possui 30 valores que tem duas varia√ß√µes em 'CALENDAR'\n",
    "print(\"=== TRATANDO Duplicatas da coluna SUMMARY ===\")\n",
    "df['CALENDAR'] = df['CALENDAR'].replace('PUC üëª', 'PUC')\n",
    "\n",
    "# Corrigindo os valores duplicados de 'Academia'\n",
    "df.loc[(df['SUMMARY'] == 'academia') & (df['CALENDAR'] == 'Pessoal'), 'CALENDAR'] = 'Exerc√≠cios' # 2\n",
    "print(f'Valores de CALENDAR para \"Academia\": {df.loc[df[\"SUMMARY\"] == \"academia\", \"CALENDAR\"].unique()}')\n",
    "\n",
    "# Corrigindo os valores duplicados de 'Aldeia'\n",
    "df.loc[(df['SUMMARY'] == 'aldeia') & (df['CALENDAR'] == 'Pessoal'), 'CALENDAR'] = 'Social' # 2\n",
    "print(f'Valores de CALENDAR para \"Aldeia\": {df.loc[df[\"SUMMARY\"] == \"aldeia\", \"CALENDAR\"].unique()}')\n",
    "\n",
    "# Corrigindo os valores duplicados de 'Alessandra'\n",
    "df.loc[(df['SUMMARY'] == 'alessandra') & (df['CALENDAR'] == 'Compromisso'), 'CALENDAR'] = 'Sa√∫de' # 2\n",
    "print(f'Valores de CALENDAR para \"Alessandra\": {df.loc[df[\"SUMMARY\"] == \"alessandra\", \"CALENDAR\"].unique()}')\n",
    "\n",
    "# Corrigindo os valores duplicados de 'Aula'\n",
    "df.loc[(df['SUMMARY'] == 'aula') & (df['CALENDAR'] == 'Pessoal'), 'CALENDAR'] = 'PUC' # 2\n",
    "print(f'Valores de CALENDAR para \"Aula\": {df.loc[df[\"SUMMARY\"] == \"aula\", \"CALENDAR\"].unique()}')\n",
    "\n",
    "# Corrigindo os valores duplicados de 'BD: T2 G2'\n",
    "df.loc[(df['SUMMARY'] == 'bd: t2 g2') & (df['CALENDAR'] == 'PUC'), 'CALENDAR'] = 'Exames' # 2\n",
    "print(f'Valores de CALENDAR para \"BD: T2 G2\": {df.loc[df[\"SUMMARY\"] == \"bd: t2 g2\", \"CALENDAR\"].unique()}')\n",
    "\n",
    "# Corrigindo os valores duplicados de 'BIRUSAMBA DE VER√ÉO'\n",
    "df.loc[(df['SUMMARY'] == 'birusamba de verao'), 'CALENDAR'] = 'Social' # 2\n",
    "print(f'Valores de CALENDAR para \"BIRUSAMBA DE VER√ÉO\": {df.loc[df[\"SUMMARY\"] == \"birusamba de verao\", \"CALENDAR\"].unique()}')\n",
    "\n",
    "# Corrigindo os valores duplicados de De-Para\n",
    "df.loc[(df['SUMMARY'] == 'de-para') & (df['CALENDAR'] == 'Exames'), 'CALENDAR'] = 'PUC' # 2\n",
    "print(f'Valores de CALENDAR para \"De-Para\": {df.loc[df[\"SUMMARY\"] == \"de-para\", \"CALENDAR\"].unique()}')\n",
    "\n",
    "# Corrigindo os valores duplicados de 'Muay Thai'\n",
    "df.loc[(df['SUMMARY'] == 'muay thai') & (df['CALENDAR'] == 'Pessoal'), 'CALENDAR'] = 'Exerc√≠cios' # 2\n",
    "print(f'Valores de CALENDAR para \"Muay Thai\": {df.loc[df[\"SUMMARY\"] == \"muay thai\", \"CALENDAR\"].unique()}')\n",
    "\n",
    "# Corrigindo valores duplicados de 'Psic√≥loga'\n",
    "df.loc[(df['SUMMARY'] == 'psicologa') & (df['CALENDAR'] == 'Compromisso'), 'CALENDAR'] = 'Sa√∫de' # 2\n",
    "print(f'Valores de CALENDAR para \"Psic√≥loga\": {df.loc[df[\"SUMMARY\"] == \"psicologa\", \"CALENDAR\"].unique()}')\n",
    "\n",
    "# Corrigindo valores duplicados de 'SO: P1' # 2\n",
    "df.loc[(df['SUMMARY'] == 'so: p1') & (df['CALENDAR'] == 'PUC'), 'CALENDAR'] = 'Exames' # 2\n",
    "print(f'Valores de CALENDAR para \"SO: P1\": {df.loc[df[\"SUMMARY\"] == \"so: p1\", \"CALENDAR\"].unique()}')\n",
    "\n",
    "# Corrigindo valores duplicados de 'Itaipava'\n",
    "df.loc[(df['SUMMARY'] == 'itaipava') & (df['CALENDAR'] == 'Pessoal'), 'CALENDAR'] = 'Social' # 2\n",
    "print(f'Valores de CALENDAR para \"Itaipava\": {df.loc[df[\"SUMMARY\"] == \"itaipava\", \"CALENDAR\"].unique()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "2b8fc837",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== ENCONTRO DE DUPLICATAS DA COLUNA SUMMARY ===\n",
      "Quantidade de duplicatas encontradas: 2\n",
      "Duplicatas encontradas:\n",
      "     SUMMARY     CALENDAR\n",
      "2     almoco  Alimenta√ß√£o\n",
      "2770  almoco      Pessoal\n"
     ]
    }
   ],
   "source": [
    "print(\"=== ENCONTRO DE DUPLICATAS DA COLUNA SUMMARY ===\")\n",
    "duplicates = df[df.duplicated(subset='SUMMARY', keep=False)]\n",
    "# Seleciona duplicatas de SUMMARY que aparecem em mais de um CALENDAR\n",
    "duplicates_sum_cal = (\n",
    "    duplicates[['SUMMARY', 'CALENDAR']]\n",
    "    .drop_duplicates()\n",
    "    .groupby('SUMMARY')\n",
    "    .filter(lambda x: x['CALENDAR'].nunique() > 1)\n",
    "    .sort_values(by=['SUMMARY', 'CALENDAR'], ascending=[True, True])\n",
    ")\n",
    "print(f\"Quantidade de duplicatas encontradas: {duplicates_sum_cal.shape[0]}\")\n",
    "print(f\"Duplicatas encontradas:\\n{duplicates_sum_cal}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13d1c931",
   "metadata": {},
   "source": [
    "## Verificando valores parecidos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cab2cf2b",
   "metadata": {},
   "source": [
    "### Passando o valor 'Alessandra' da coluna SUMMARY para 'Psic√≥loga'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "6c0224af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantidade de valores √∫nicos antes da unifica√ß√£o: 324\n",
      "=== TROCANDO DE \"alessandra\" para \"psiquiatra\" ===\n",
      "Quantidade de valores √∫nicos depois da unifica√ß√£o: 323\n",
      "\n",
      "Valores que come√ßam com 'psi' antes da unifica√ß√£o: ['psiquiatra' 'psicologa' 'psicologo']\n",
      "=== TROCANDO DE \"psicologa\" para \"psicologo\" ===\n",
      "Valores que come√ßam com 'psi' depois da unifica√ß√£o: ['psiquiatra' 'psicologo']\n"
     ]
    }
   ],
   "source": [
    "print(f\"Quantidade de valores √∫nicos antes da unifica√ß√£o: {df['SUMMARY'].nunique()}\")\n",
    "\n",
    "print('=== TROCANDO DE \"alessandra\" para \"psiquiatra\" ===')\n",
    "df.loc[df['SUMMARY'] == 'alessandra', 'SUMMARY'] = 'psiquiatra'\n",
    "\n",
    "print(f\"Quantidade de valores √∫nicos depois da unifica√ß√£o: {df['SUMMARY'].nunique()}\")\n",
    "\n",
    "\n",
    "psi_values = df[df['SUMMARY'].str.lower().str.startswith('psi', na=False)]['SUMMARY'].unique()\n",
    "print(f\"\\nValores que come√ßam com 'psi' antes da unifica√ß√£o: {psi_values}\")\n",
    "\n",
    "print('=== TROCANDO DE \"psicologa\" para \"psicologo\" ===')\n",
    "df.loc[df['SUMMARY'] == 'psicologa', 'SUMMARY'] = 'psicologo'\n",
    "\n",
    "psi_values = df[df['SUMMARY'].str.lower().str.startswith('psi', na=False)]['SUMMARY'].unique()\n",
    "print(f\"Valores que come√ßam com 'psi' depois da unifica√ß√£o: {psi_values}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c3288d3",
   "metadata": {},
   "source": [
    "## Melhorando valores com INF, MAT ou ADM no inicio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e95ec778",
   "metadata": {},
   "source": [
    "### Verificando todos os valores que possuem inf, mat ou adm no inicio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "577e1cc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Avaliando valores que come√ßam com \"inf\", \"mat\" ou \"adm\"\n",
      "Quantidade de valores √∫nicos: 33\n",
      "Valores:\n",
      "SUMMARY\n",
      "inf1410 - gerenc proj inf                     39\n",
      "adm1019 - intr. financas                      38\n",
      "inf1629 - p. eng. de software                 38\n",
      "mat4162 - calculo ii                          38\n",
      "inf1608 - analise numerica                    38\n",
      "inf1307 - games                               36\n",
      "inf1316 - so                                  36\n",
      "inf1771 - ia                                  36\n",
      "inf1403 - ihc                                 35\n",
      "inf1022 - als                                 35\n",
      "inf1350 - prog sis reat                       34\n",
      "inf1027 - teste e medicao de software         33\n",
      "inf1036 - prob comp                           32\n",
      "inf1640 - redes de computadores               31\n",
      "inf1636 - programacao orientada a objetos     31\n",
      "inf1631 - estruturas discretas                31\n",
      "inf1028 - projeto e construcao de sistemas    30\n",
      "inf1721 - aa                                  30\n",
      "inf1032 - ciencia de dados                    29\n",
      "inf1010 - eda                                 23\n",
      "inf1383 - bancos de dados                     19\n",
      "inf1314 - startup ia                          19\n",
      "inf1338 - llm                                 18\n",
      "mat1260 - algebra linear 1                     8\n",
      "inf1018 - software basico                      8\n",
      "inf1301 - programacao modular                  6\n",
      "inf1022 - analisadores lex. e sint.            4\n",
      "matricula puc                                  4\n",
      "mat1162 - calculo a varias variaveis i         3\n",
      "inf2471 - prob comp                            2\n",
      "inf1018 - monitoria                            1\n",
      "inf1920 - aula expositiva                      1\n",
      "inf1301 - relatorio plano de acao              1\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print('=== Avaliando valores que come√ßam com \"inf\", \"mat\" ou \"adm\"')\n",
    "\n",
    "inf_mat_values = df.loc[\n",
    "    df['SUMMARY'].str.lower().str.startswith('adm', na=False) |\n",
    "    df['SUMMARY'].str.lower().str.startswith('inf', na=False) |\n",
    "    df['SUMMARY'].str.lower().str.startswith('mat', na=False),\n",
    "    'SUMMARY'\n",
    "]\n",
    "print(f'Quantidade de valores √∫nicos: {inf_mat_values.nunique()}')\n",
    "\n",
    "print(f'Valores:\\n{inf_mat_values.value_counts()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ae17424",
   "metadata": {},
   "source": [
    "### Retirando INF2471 - Prob Comp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "afda6568",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N√∫mero de linhas antes de retirar inf2471 - prob comp:  4372\n",
      "N√∫mero de linhas depois de retirar inf2471 - prob comp:  4370\n"
     ]
    }
   ],
   "source": [
    "print('N√∫mero de linhas antes de retirar inf2471 - prob comp: ', len(df))\n",
    "df = df[df['SUMMARY'] != 'inf2471 - prob comp']\n",
    "print('N√∫mero de linhas depois de retirar inf2471 - prob comp: ', len(df))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d15c9bcf",
   "metadata": {},
   "source": [
    "### Retirando MAT1162 - CALCULO A VARIAS VARIAVEIS I"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "767d54de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N√∫mero de linhas antes de retirar mat1162 - calculo a varias variaveis i:  4370\n",
      "N√∫mero de linhas depois de retirar mat1162 - calculo a varias variaveis i:  4367\n"
     ]
    }
   ],
   "source": [
    "print('N√∫mero de linhas antes de retirar mat1162 - calculo a varias variaveis i: ', len(df))\n",
    "df = df[df['SUMMARY'] != 'mat1162 - calculo a varias variaveis i']\n",
    "print('N√∫mero de linhas depois de retirar mat1162 - calculo a varias variaveis i: ', len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c98bce17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Expans√£o de abrevia√ß√µes conclu√≠da - tudo em min√∫sculo!\n"
     ]
    }
   ],
   "source": [
    "# Corrigir primeiro c√≥digo que j√° estava sendo tratado\n",
    "df.loc[df['SUMMARY'] == 'inf1410 - gerenc proj inf', 'SUMMARY'] = 'inf1410 - gerencia de projetos de informatica'\n",
    "\n",
    "# INF1629 - P. Eng. de Software\n",
    "df.loc[df['SUMMARY'] == 'inf1629 - p. eng. de software', 'SUMMARY'] = 'inf1629 - principios de engenharia de software'\n",
    "\n",
    "# INF1314 - Startup IA\n",
    "df.loc[df['SUMMARY'] == 'inf1314 - startup ia', 'SUMMARY'] = 'inf1314 - gerando startup com inteligencia artificial'\n",
    "\n",
    "# INF1771 - IA\n",
    "df.loc[df['SUMMARY'] == 'inf1771 - ia', 'SUMMARY'] = 'inf1771 - inteligencia artificial'\n",
    "\n",
    "# INF1307 - Games\n",
    "df.loc[df['SUMMARY'] == 'inf1307 - games', 'SUMMARY'] = 'inf1307 - desenvolvimento de jogos'\n",
    "\n",
    "# INF1316 - SO\n",
    "df.loc[df['SUMMARY'] == 'inf1316 - so', 'SUMMARY'] = 'inf1316 - sistemas operacionais'\n",
    "\n",
    "# INF1403 - IHC\n",
    "df.loc[df['SUMMARY'] == 'inf1403 - ihc', 'SUMMARY'] = 'inf1403 - interacao humano computador'\n",
    "\n",
    "# INF1022 - ALS\n",
    "df.loc[df['SUMMARY'] == 'inf1022 - als', 'SUMMARY'] = 'inf1022 - analisadores lexicos e sintaticos'\n",
    "\n",
    "# INF1350 - Prog Sis Reat\n",
    "df.loc[df['SUMMARY'] == 'inf1350 - prog sis reat', 'SUMMARY'] = 'inf1350 - programacao de sistemas reativos'\n",
    "\n",
    "# INF1036 - Prob Comp\n",
    "df.loc[df['SUMMARY'] == 'inf1036 - prob comp', 'SUMMARY'] = 'inf1036 - probabilidade computacional'\n",
    "\n",
    "# INF1721 - AA\n",
    "df.loc[df['SUMMARY'] == 'inf1721 - aa', 'SUMMARY'] = 'inf1721 - analise de algoritmos'\n",
    "\n",
    "# INF1010 - EDA\n",
    "df.loc[df['SUMMARY'] == 'inf1010 - eda', 'SUMMARY'] = 'inf1010 - estruturas de dados avan√ßadas'\n",
    "\n",
    "# INF1338 - LLM\n",
    "df.loc[df['SUMMARY'] == 'inf1338 - llm', 'SUMMARY'] = 'inf1338 - large language models'\n",
    "\n",
    "# INF1022 - Analisadores L√©x. e Sint.\n",
    "df.loc[df['SUMMARY'] == 'inf1022 - analisadores lex. e sint.', 'SUMMARY'] = 'inf1022 - analisadores lexicos e sintaticos'\n",
    "\n",
    "df.loc[df['SUMMARY'] == 'adm1019 - intr. financas', 'SUMMARY'] = 'adm1019 - introducao a finan√ßas'\n",
    "\n",
    "print('Expans√£o de abrevia√ß√µes conclu√≠da - tudo em min√∫sculo!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b60e317",
   "metadata": {},
   "source": [
    "### Verificando novamente os valores com INF, MAT ou ADM no inicio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "4ca40727",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Avaliando valores que come√ßam com \"inf\", \"mat\" ou \"adm\"\n",
      "Quantidade de valores √∫nicos: 30\n",
      "Valores:\n",
      "SUMMARY\n",
      "inf1410 - gerencia de projetos de informatica            39\n",
      "inf1022 - analisadores lexicos e sintaticos              39\n",
      "adm1019 - introducao a finan√ßas                          38\n",
      "inf1629 - principios de engenharia de software           38\n",
      "mat4162 - calculo ii                                     38\n",
      "inf1608 - analise numerica                               38\n",
      "inf1771 - inteligencia artificial                        36\n",
      "inf1316 - sistemas operacionais                          36\n",
      "inf1307 - desenvolvimento de jogos                       36\n",
      "inf1403 - interacao humano computador                    35\n",
      "inf1350 - programacao de sistemas reativos               34\n",
      "inf1027 - teste e medicao de software                    33\n",
      "inf1036 - probabilidade computacional                    32\n",
      "inf1631 - estruturas discretas                           31\n",
      "inf1636 - programacao orientada a objetos                31\n",
      "inf1640 - redes de computadores                          31\n",
      "inf1028 - projeto e construcao de sistemas               30\n",
      "inf1721 - analise de algoritmos                          30\n",
      "inf1032 - ciencia de dados                               29\n",
      "inf1010 - estruturas de dados avan√ßadas                  23\n",
      "inf1383 - bancos de dados                                19\n",
      "inf1314 - gerando startup com inteligencia artificial    19\n",
      "inf1338 - large language models                          18\n",
      "mat1260 - algebra linear 1                                8\n",
      "inf1018 - software basico                                 8\n",
      "inf1301 - programacao modular                             6\n",
      "matricula puc                                             4\n",
      "inf1018 - monitoria                                       1\n",
      "inf1920 - aula expositiva                                 1\n",
      "inf1301 - relatorio plano de acao                         1\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print('=== Avaliando valores que come√ßam com \"inf\", \"mat\" ou \"adm\"')\n",
    "\n",
    "inf_mat_values = df.loc[\n",
    "    df['SUMMARY'].str.lower().str.startswith('adm', na=False) |\n",
    "    df['SUMMARY'].str.lower().str.startswith('inf', na=False) |\n",
    "    df['SUMMARY'].str.lower().str.startswith('mat', na=False),\n",
    "    'SUMMARY'\n",
    "]\n",
    "print(f'Quantidade de valores √∫nicos: {inf_mat_values.nunique()}')\n",
    "\n",
    "print(f'Valores:\\n{inf_mat_values.value_counts()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af3ff7d3",
   "metadata": {},
   "source": [
    "## Verbalizar tarefas e anonimizar pessoas (com llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "e8a7f26a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exportar tuplas √∫nicas de (SUMMARY, CALENDAR) para CSV\n",
    "# df[['SUMMARY', 'CALENDAR']].drop_duplicates().to_csv('../data/summary_calendar_unique.csv', index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eebdfca6",
   "metadata": {},
   "source": [
    "### Colocando as tarefas nos (SUMMARY, CALENDAR) √∫nicos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc873f14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== INTEGRANDO TASKS VERBALIZADAS EM INGL√äS ===\n",
      "Tasks verbalizadas carregadas: 320 registros\n",
      "Mapeamento criado para 320 tuplas √∫nicas\n",
      "\n",
      "Resultados do mapeamento:\n",
      "‚úÖ Registros com t√≠tulo atribu√≠do: 4339\n",
      "‚ùå Registros sem t√≠tulo: 28\n",
      "üìä Taxa de sucesso: 99.36%\n",
      "\n",
      "=== EXEMPLOS DOS DADOS INTEGRADOS ===\n",
      "           SUMMARY     CALENDAR                    TITLE\n",
      "0    cafe da manha  Alimenta√ß√£o           Have breakfast\n",
      "1  lanche da manha  Alimenta√ß√£o     Have a morning snack\n",
      "2           almoco  Alimenta√ß√£o               Have lunch\n",
      "3  lanche da tarde  Alimenta√ß√£o  Have an afternoon snack\n",
      "4       pre-treino  Alimenta√ß√£o         Take pre-workout\n",
      "5           jantar  Alimenta√ß√£o              Have dinner\n",
      "6    cafe da manha  Alimenta√ß√£o           Have breakfast\n",
      "7  lanche da manha  Alimenta√ß√£o     Have a morning snack\n",
      "8           almoco  Alimenta√ß√£o               Have lunch\n",
      "9  lanche da tarde  Alimenta√ß√£o  Have an afternoon snack\n",
      "\n",
      "=== REGISTROS N√ÉO MAPEADOS ===\n",
      "Tuplas √∫nicas n√£o mapeadas: 27\n",
      "                                  SUMMARY     CALENDAR\n",
      "1245                                   rm  Compromisso\n",
      "1248                                 zion  Compromisso\n",
      "1289                          visita rede  Compromisso\n",
      "1291                  mago da musica link  Compromisso\n",
      "1445                        viviane nutri        Sa√∫de\n",
      "1446                           dra. vania        Sa√∫de\n",
      "1711                       academia ideal   Exerc√≠cios\n",
      "2281                        aula da liane      Pessoal\n",
      "2282                       casa do felipe      Pessoal\n",
      "2326                             amazonia      Pessoal\n",
      "2775                           primo rico      Pessoal\n",
      "2778   reuniao de cronograma do acessorio      Pessoal\n",
      "2779                      corte masculino      Pessoal\n",
      "2784            call checkpoint acessorio      Pessoal\n",
      "2788                   gravacao acessorio      Pessoal\n",
      "2789                                 fone      Pessoal\n",
      "2797                avaliacao imobiliaria      Pessoal\n",
      "2798                       wwdc ilearning      Pessoal\n",
      "2800  mentoria inversu (felipe gameleira)      Pessoal\n",
      "2802  mentoria inversu - felipe gameleira      Pessoal\n",
      "3746                       ingresso harry       Social\n",
      "3749                                 thor       Social\n",
      "3750                         the avengers       Social\n",
      "3751                      rafael portugal       Social\n",
      "3767                        pulo big jump       Social\n",
      "3768                       resenha felipe       Social\n",
      "3782                             festa re       Social\n",
      "\n",
      "=== REMOVENDO REGISTROS SEM T√çTULO ===\n",
      "Registros antes da remo√ß√£o: 4367\n",
      "Registros ap√≥s remo√ß√£o: 4339\n",
      "‚úÖ Removidos 28 registros sem t√≠tulo\n"
     ]
    }
   ],
   "source": [
    "# Carregar as tasks verbalizadas e integrar com o dataset original\n",
    "print(\"=== INTEGRANDO TASKS VERBALIZADAS EM INGL√äS ===\")\n",
    "\n",
    "# Carregar o arquivo com as tasks verbalizadas\n",
    "formatted_tasks_df = pd.read_csv('../data/fixed/formatted_tasks.csv', encoding='utf-8')\n",
    "print(f\"Tasks verbalizadas carregadas: {len(formatted_tasks_df)} registros\")\n",
    "\n",
    "# Criar um dicion√°rio para mapear (SUMMARY, CALENDAR) -> TASK_EN\n",
    "task_mapping = {}\n",
    "for _, row in formatted_tasks_df.iterrows():\n",
    "    key = (row['SUMMARY'], row['CALENDAR'])\n",
    "    task_mapping[key] = row['TASK_EN']\n",
    "\n",
    "print(f\"Mapeamento criado para {len(task_mapping)} tuplas √∫nicas\")\n",
    "\n",
    "# Adicionar a coluna TITLE ao dataset original (usando TASK_EN)\n",
    "df['TITLE'] = df.apply(lambda row: task_mapping.get((row['SUMMARY'], row['CALENDAR']), ''), axis=1)\n",
    "\n",
    "# Verificar quantos registros foram mapeados\n",
    "mapped_count = len(df[df['TITLE'] != ''])\n",
    "unmapped_count = len(df[df['TITLE'] == ''])\n",
    "\n",
    "print(f\"\\nResultados do mapeamento:\")\n",
    "print(f\"Registros com t√≠tulo atribu√≠do: {mapped_count}\")\n",
    "print(f\"Registros sem t√≠tulo: {unmapped_count}\")\n",
    "print(f\"Taxa de sucesso: {(mapped_count / len(df) * 100):.2f}%\")\n",
    "\n",
    "# Mostrar exemplos dos dados integrados\n",
    "print(f\"\\n=== EXEMPLOS DOS DADOS INTEGRADOS ===\")\n",
    "print(df[['SUMMARY', 'CALENDAR', 'TITLE']].head(10))\n",
    "\n",
    "# Verificar se h√° registros n√£o mapeados\n",
    "if unmapped_count > 0:\n",
    "    print(f\"\\n=== REGISTROS N√ÉO MAPEADOS ===\")\n",
    "    # Mostrar todos os n√£o mapeados\n",
    "    unmapped_df = df[df['TITLE'] == ''][['SUMMARY', 'CALENDAR']].drop_duplicates()\n",
    "    print(f\"Tuplas √∫nicas n√£o mapeadas: {len(unmapped_df)}\")\n",
    "    print(unmapped_df)\n",
    "\n",
    "    # Remover registros sem TITLE usando a mesma l√≥gica do unmapped_count\n",
    "    print(f\"\\n=== REMOVENDO REGISTROS SEM T√çTULO ===\")\n",
    "    print(f\"Registros antes da remo√ß√£o: {len(df)}\")\n",
    "    df = df[df['TITLE'] != '']  # Filtra apenas registros COM t√≠tulo\n",
    "    print(f\"Registros ap√≥s remo√ß√£o: {len(df)}\")\n",
    "    print(f\"Removidos {unmapped_count} registros sem t√≠tulo\")\n",
    "else:\n",
    "    print(\"\\nTodos os registros j√° possuem t√≠tulo!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d84906ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== VERIFICA√á√ÉO FINAL ===\n",
      "Total de registros no dataset: 4339\n",
      "Registros com TITLE vazio: 0\n",
      "Registros com TITLE preenchido: 4339\n",
      "‚úÖ SUCESSO: Todos os registros possuem TITLE!\n"
     ]
    }
   ],
   "source": [
    "# Verificar se todos os registros agora possuem TITLE\n",
    "print(\"=== VERIFICA√á√ÉO FINAL ===\")\n",
    "print(f\"Total de registros no dataset: {len(df)}\")\n",
    "print(f\"Registros com TITLE vazio: {len(df[df['TITLE'] == ''])}\")\n",
    "print(f\"Registros com TITLE preenchido: {len(df[df['TITLE'] != ''])}\")\n",
    "\n",
    "if len(df[df['TITLE'] == '']) == 0:\n",
    "    print(\"SUCESSO: Todos os registros possuem TITLE!\")\n",
    "else:\n",
    "    print(\"ERRO: Ainda h√° registros sem TITLE\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9adf33a",
   "metadata": {},
   "source": [
    "## Verificar a coluna TITLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "92f44282",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== VERIFICA√á√ÉO DA COLUNA TITLE ===\n",
      "Valores √∫nicos na coluna TITLE: 270\n",
      "Exemplos de t√≠tulos:\n",
      "['Take Modular Programming exam 1', 'Take Calculus exam 3', 'Take database test 3', 'Do bioimpedance', 'Attend inf1383 - Databases class']\n"
     ]
    }
   ],
   "source": [
    "# A coluna TITLE j√° vem formatada em ingl√™s do arquivo formatted_tasks.csv\n",
    "# N√£o √© necess√°rio aplicar normaliza√ß√£o adicional\n",
    "print(\"=== VERIFICA√á√ÉO DA COLUNA TITLE ===\")\n",
    "print(f\"Valores √∫nicos na coluna TITLE: {df['TITLE'].nunique()}\")\n",
    "print(f\"Exemplos de t√≠tulos:\")\n",
    "print(df['TITLE'].drop_duplicates().sample(5, random_state=42).tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76309981",
   "metadata": {},
   "source": [
    "## Descartar tarefas que cobrem o dia inteiro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "ab619ec8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== DESCARTANDO TAREFAS QUE COBREM O DIA INTEIRO ===\n",
      "Tarefas que cobrem o dia inteiro encontradas: 304\n",
      "Total de registros ap√≥s descartar tarefas de 24h: 4035\n"
     ]
    }
   ],
   "source": [
    "print('=== DESCARTANDO TAREFAS QUE COBREM O DIA INTEIRO ===')\n",
    "    # Filtrar tarefas que come√ßam e terminam exatamente √†s 00:00 e duram 24 horas\n",
    "mask = (\n",
    "    (pd.to_datetime(df['DTSTART']).dt.hour == 0) &\n",
    "    (pd.to_datetime(df['DTSTART']).dt.minute == 0) &\n",
    "    (pd.to_datetime(df['DTEND']).dt.hour == 0) &\n",
    "    (pd.to_datetime(df['DTEND']).dt.minute == 0) &\n",
    "    (df['DURATION'] == 24.0)\n",
    ")\n",
    "print(f'Tarefas que cobrem o dia inteiro encontradas: {mask.sum()}')\n",
    "df = df[~mask]\n",
    "print(f'Total de registros ap√≥s descartar tarefas de 24h: {len(df)}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47ababe5",
   "metadata": {},
   "source": [
    "# Exportar DataFrame completo para CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a4b3e16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== SALVANDO DATASET PROCESSADO ===\n",
      "‚úÖ Dataset processado salvo em: ../data/tasks_summary.csv\n",
      "\n",
      "=== ESTAT√çSTICAS FINAIS ===\n",
      "Total de registros: 4035\n",
      "Total de colunas: 7\n",
      "Categorias √∫nicas: 11\n",
      "T√≠tulos √∫nicos: 215\n"
     ]
    }
   ],
   "source": [
    "# # Salvar dataset processado\n",
    "print(\"=== SALVANDO DATASET PROCESSADO ===\")\n",
    "\n",
    "# Salvar como CSV processado\n",
    "output_path = '../data/tasks_summary.csv'\n",
    "df.to_csv(output_path, index=False, encoding='utf-8')\n",
    "print(f\"Dataset processado salvo em: {output_path}\")\n",
    "\n",
    "# Estat√≠sticas finais\n",
    "print(f\"\\n=== ESTAT√çSTICAS FINAIS ===\")\n",
    "print(f\"Total de registros: {len(df)}\")\n",
    "print(f\"Total de colunas: {len(df.columns)}\")\n",
    "print(f\"Categorias √∫nicas: {df['CALENDAR'].nunique()}\")\n",
    "print(f\"T√≠tulos √∫nicos: {df['TITLE'].nunique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "d8ee6603",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== AMOSTRA DO DATASET FINAL ===\n",
      "Colunas do dataset final:\n",
      "['SUMMARY', 'DTSTART', 'DTEND', 'CALENDAR', 'DURATION', 'CREATED', 'TITLE']\n",
      "\n",
      "Primeiros 5 registros:\n",
      "           SUMMARY             DTSTART               DTEND     CALENDAR  \\\n",
      "0    cafe da manha 2025-01-07 08:00:00 2025-01-07 08:20:00  Alimenta√ß√£o   \n",
      "1  lanche da manha 2025-01-07 10:00:00 2025-01-07 10:05:00  Alimenta√ß√£o   \n",
      "2           almoco 2025-01-07 12:30:00 2025-01-07 13:00:00  Alimenta√ß√£o   \n",
      "3  lanche da tarde 2025-01-07 16:00:00 2025-01-07 16:15:00  Alimenta√ß√£o   \n",
      "4       pre-treino 2025-01-07 18:00:00 2025-01-07 18:05:00  Alimenta√ß√£o   \n",
      "\n",
      "   DURATION             CREATED                    TITLE  \n",
      "0  0.333333 2025-01-07 10:12:00           Have breakfast  \n",
      "1  0.083333 2025-01-07 10:14:00     Have a morning snack  \n",
      "2  0.500000 2025-01-07 10:15:00               Have lunch  \n",
      "3  0.250000 2025-01-07 10:16:00  Have an afternoon snack  \n",
      "4  0.083333 2025-01-07 10:17:00         Take pre-workout  \n",
      "\n",
      "Tipos de dados:\n",
      "SUMMARY             object\n",
      "DTSTART     datetime64[ns]\n",
      "DTEND       datetime64[ns]\n",
      "CALENDAR            object\n",
      "DURATION           float64\n",
      "CREATED     datetime64[ns]\n",
      "TITLE               object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Mostrar amostra do dataset final\n",
    "print(\"=== AMOSTRA DO DATASET FINAL ===\")\n",
    "print(\"Colunas do dataset final:\")\n",
    "print(df.columns.tolist())\n",
    "print(f\"\\nPrimeiros 5 registros:\")\n",
    "print(df.head())\n",
    "print(f\"\\nTipos de dados:\")\n",
    "print(df.dtypes)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm-task-scheduler-py3.13",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
