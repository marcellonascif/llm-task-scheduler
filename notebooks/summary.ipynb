{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "379d5361",
   "metadata": {},
   "source": [
    "# Pr√© processamento da coluna SUMMARY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "29fcfc92",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import unicodedata\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "8fed6f22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV carregado com engine C! 7232 linhas encontradas.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    df = pd.read_csv(\n",
    "        '../data/tasks.csv',\n",
    "        encoding='utf-8',\n",
    "        sep=\",\",\n",
    "        quotechar='\"',\n",
    "        on_bad_lines='skip',      # ignora linhas corrompidas\n",
    "        dtype=str,               # carrega tudo como string, depois ajusta\n",
    "        engine='c'          # usa engine python que √© mais tolerante\n",
    "    )\n",
    "    print(f\"CSV carregado com engine C! {len(df)} linhas encontradas.\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Erro ao ler CSV: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "0a06b66e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== INFORMA√á√ïES B√ÅSICAS DO DATASET ===\n",
      "Shape: (7232, 17)\n",
      "\n",
      "Resumo da coluna SUMMARY:\n",
      "  - Tipo de dado: object\n",
      "  - Valores √∫nicos: 376\n",
      "  - Valores nulos: 0\n",
      "  - Primeiros 5 valores:\n",
      "0     üç≥\n",
      "1     üßã\n",
      "2    üçΩÔ∏è\n",
      "3     ü•™\n",
      "4     üçå\n",
      "Name: SUMMARY, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Verificar informa√ß√µes b√°sicas do dataset\n",
    "print(\"=== INFORMA√á√ïES B√ÅSICAS DO DATASET ===\")\n",
    "print(f\"Shape: {df.shape}\")\n",
    "# Informa√ß√µes apenas da coluna SUMMARY\n",
    "print(f\"\\nResumo da coluna SUMMARY:\")\n",
    "print(f\"  - Tipo de dado: {df['SUMMARY'].dtype}\")\n",
    "print(f\"  - Valores √∫nicos: {df['SUMMARY'].nunique()}\")\n",
    "print(f\"  - Valores nulos: {df['SUMMARY'].isnull().sum()}\")\n",
    "print(f\"  - Primeiros 5 valores:\\n{df['SUMMARY'].head()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f16a371f",
   "metadata": {},
   "source": [
    "### An√°lise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "2cd70207",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== AN√ÅlISE DA COLUNA SUMMARY ===\n",
      "Quantidade de valores √∫nicos: 376\n",
      "Valores √∫nicos exportados para ../data/title_unique.csv\n"
     ]
    }
   ],
   "source": [
    "print(\"=== AN√ÅlISE DA COLUNA SUMMARY ===\")\n",
    "\n",
    "print(f\"Quantidade de valores √∫nicos: {df['SUMMARY'].nunique()}\")\n",
    "# print(f\"Valores √∫nicos: {df['SUMMARY'].unique()}\")\n",
    "\n",
    "# Exportar valores √∫nicos da coluna SUMMARY para uma tabela CSV e usar uma LLM para clusterizar informacoes parecidas\n",
    "unique_summary = df[['SUMMARY', 'CALENDAR']].drop_duplicates().rename(columns={'SUMMARY': 'TITLE'})\n",
    "unique_summary = unique_summary.sort_values(by='TITLE').reset_index(drop=True)\n",
    "unique_summary.to_csv('../data/title_calendar_unique.csv', index=False, encoding='utf-8')\n",
    "print(\"Valores √∫nicos exportados para ../data/title_unique.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dbda371",
   "metadata": {},
   "source": [
    "## Limpando"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "3ddcfa37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Avalia√ß√£o da coluna SUMMARY antes da normaliza√ß√£o ===\n",
      "Valores √∫nicos: 376\n",
      "Exemplos: ['üç≥', 'üßã', 'üçΩÔ∏è', 'ü•™', 'üçå', 'INF1410 - Gerenc Proj Inf', 'INF1608 - An√°lise Num√©rica', 'ADM1019 - Intr. Finan√ßas', 'INF1629 - P. Eng. de Software', 'Parab√©ns!']\n",
      "\n",
      "=== Avalia√ß√£o da coluna SUMMARY_NORM depois da normaliza√ß√£o ===\n",
      "Valores √∫nicos: 372\n",
      "Exemplos: ['üç≥', 'üßã', 'üçΩÔ∏è', 'ü•™', 'üçå', 'inf1410 gerenc proj inf', 'inf1608 an√°lise num√©rica', 'adm1019 intr finan√ßas', 'inf1629 p eng de software', 'parab√©ns']\n"
     ]
    }
   ],
   "source": [
    "# Avalia√ß√£o antes da normaliza√ß√£o\n",
    "print(\"=== Avalia√ß√£o da coluna SUMMARY antes da normaliza√ß√£o ===\")\n",
    "print(f\"Valores √∫nicos: {df['SUMMARY'].nunique()}\")\n",
    "print(f\"Exemplos: {df['SUMMARY'].drop_duplicates().head(10).tolist()}\")\n",
    "\n",
    "def normalize_text(text):\n",
    "    if pd.isnull(text):\n",
    "        return \"\"\n",
    "    # Lowercase\n",
    "    text = text.lower()\n",
    "    # Remove accents\n",
    "    # text = unicodedata.normalize('NFKD', text).encode('ASCII', 'ignore').decode('utf-8')\n",
    "    # Remove punctuation\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "    # Remove extra spaces\n",
    "    text = ' '.join(text.split())\n",
    "    return text\n",
    "\n",
    "df['SUMMARY_NORM'] = df['SUMMARY'].apply(normalize_text)\n",
    "\n",
    "# Avalia√ß√£o depois da normaliza√ß√£o\n",
    "print(\"\\n=== Avalia√ß√£o da coluna SUMMARY_NORM depois da normaliza√ß√£o ===\")\n",
    "print(f\"Valores √∫nicos: {df['SUMMARY_NORM'].nunique()}\")\n",
    "print(f\"Exemplos: {df['SUMMARY_NORM'].drop_duplicates().head(10).tolist()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2b76e0d",
   "metadata": {},
   "source": [
    "### Tratando valores da coluna SUMMARY que possuem dois valores na coluna CALENDAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "f2b23e31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== TRATANDO Duplicatas da coluna SUMMARY ===\n",
      "Valores de CALENDAR para \"Academia\": ['Exerc√≠cios']\n",
      "Valores de CALENDAR para \"Aldeia\": ['Social']\n",
      "Valores de CALENDAR para \"Alessandra\": ['Sa√∫de']\n",
      "Valores de CALENDAR para \"Aula\": ['PUC']\n",
      "Valores de CALENDAR para \"BD: T2 G2\": ['Exames']\n",
      "Valores de CALENDAR para \"BIRUSAMBA DE VER√ÉO\": ['Social']\n",
      "Valores de CALENDAR para \"De-Para\": ['PUC']\n",
      "Valores de CALENDAR para \"Muay Thai\": ['Exerc√≠cios']\n",
      "Valores de CALENDAR para \"Psic√≥loga\": ['Sa√∫de']\n",
      "Valores de CALENDAR para \"SO: P1\": ['Exames']\n"
     ]
    }
   ],
   "source": [
    "# Coluna SUMMARY possui 30 valores que tem duas varia√ß√µes em 'CALENDAR'\n",
    "print(\"=== TRATANDO Duplicatas da coluna SUMMARY ===\")\n",
    "df['CALENDAR'] = df['CALENDAR'].replace('PUC üëª', 'PUC')\n",
    "\n",
    "# Corrigindo os valores duplicados de 'Academia'\n",
    "df.loc[(df['SUMMARY'] == 'Academia') & (df['CALENDAR'] == 'Pessoal'), 'CALENDAR'] = 'Exerc√≠cios' # 2\n",
    "print(f'Valores de CALENDAR para \"Academia\": {df.loc[df['SUMMARY'] == 'Academia', 'CALENDAR'].unique()}')\n",
    "\n",
    "# Corrigindo os valores duplicados de 'Aldeia'\n",
    "df.loc[(df['SUMMARY'] == 'Aldeia') & (df['CALENDAR'] == 'Pessoal'), 'CALENDAR'] = 'Social' # 2\n",
    "print(f'Valores de CALENDAR para \"Aldeia\": {df.loc[df['SUMMARY'] == 'Aldeia', 'CALENDAR'].unique()}')\n",
    "\n",
    "# Corrigindo os valores duplicados de 'Alessandra'\n",
    "df.loc[(df['SUMMARY'] == 'Alessandra') & (df['CALENDAR'] == 'Compromisso'), 'CALENDAR'] = 'Sa√∫de' # 2\n",
    "print(f'Valores de CALENDAR para \"Alessandra\": {df.loc[df[\"SUMMARY\"] == \"Alessandra\", \"CALENDAR\"].unique()}')\n",
    "\n",
    "# Corrigindo os valores duplicados de 'Aula'\n",
    "df.loc[(df['SUMMARY'] == 'Aula') & (df['CALENDAR'] == 'Pessoal'), 'CALENDAR'] = 'PUC' # 2\n",
    "print(f'Valores de CALENDAR para \"Aula\": {df.loc[df['SUMMARY'] == 'Aula', 'CALENDAR'].unique()}')\n",
    "\n",
    "# Corrigindo os valores duplicados de 'BD: T2 G2'\n",
    "df.loc[(df['SUMMARY'] == 'BD: T2 G2') & (df['CALENDAR'] == 'PUC'), 'CALENDAR'] = 'Exames' # 2\n",
    "print(f'Valores de CALENDAR para \"BD: T2 G2\": {df.loc[df['SUMMARY'] == 'BD: T2 G2', 'CALENDAR'].unique()}')\n",
    "\n",
    "# Corrigindo os valores duplicados de 'BIRUSAMBA DE VER√ÉO'\n",
    "df.loc[(df['SUMMARY'] == 'BIRUSAMBA DE VER√ÉO'), 'CALENDAR'] = 'Social' # 2\n",
    "print(f'Valores de CALENDAR para \"BIRUSAMBA DE VER√ÉO\": {df.loc[df['SUMMARY'] == 'BIRUSAMBA DE VER√ÉO', 'CALENDAR'].unique()}')\n",
    "\n",
    "# Corrigindo os valores duplicados de De-Para\n",
    "df.loc[(df['SUMMARY'] == 'De-Para') & (df['CALENDAR'] == 'Exames'), 'CALENDAR'] = 'PUC' # 2\n",
    "print(f'Valores de CALENDAR para \"De-Para\": {df.loc[df[\"SUMMARY\"] == \"De-Para\", \"CALENDAR\"].unique()}')\n",
    "\n",
    "# Corrigindo os valores duplicados de 'Muay Thai'\n",
    "df.loc[(df['SUMMARY'] == 'Muay Thai') & (df['CALENDAR'] == 'Pessoal'), 'CALENDAR'] = 'Exerc√≠cios' # 2\n",
    "print(f'Valores de CALENDAR para \"Muay Thai\": {df.loc[df[\"SUMMARY\"] == \"Muay Thai\", \"CALENDAR\"].unique()}')\n",
    "\n",
    "# Corrigindo valores duplicados de 'Psic√≥loga'\n",
    "df.loc[(df['SUMMARY'] == 'Psic√≥loga') & (df['CALENDAR'] == 'Compromisso'), 'CALENDAR'] = 'Sa√∫de' # 2\n",
    "print(f'Valores de CALENDAR para \"Psic√≥loga\": {df.loc[df[\"SUMMARY\"] == \"Psic√≥loga\", \"CALENDAR\"].unique()}')\n",
    "\n",
    "# Corrigindo valores duplicados de 'SO: P1' # 2\n",
    "df.loc[(df['SUMMARY'] == 'SO: P1') & (df['CALENDAR'] == 'PUC'), 'CALENDAR'] = 'Exames' # 2\n",
    "print(f'Valores de CALENDAR para \"SO: P1\": {df.loc[df[\"SUMMARY\"] == \"SO: P1\", \"CALENDAR\"].unique()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "2b8fc837",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== ENCONTRO DE DUPLICATAS DA COLUNA SUMMARY ===\n",
      "Quantidade de duplicatas encontradas: 2\n",
      "Duplicatas encontradas:\n",
      "       SUMMARY CALENDAR\n",
      "4566  Itaipava  Pessoal\n",
      "5951  Itaipava   Social\n"
     ]
    }
   ],
   "source": [
    "print(\"=== ENCONTRO DE DUPLICATAS DA COLUNA SUMMARY ===\")\n",
    "duplicates = df[df.duplicated(subset='SUMMARY', keep=False)]\n",
    "# Seleciona duplicatas de SUMMARY que aparecem em mais de um CALENDAR\n",
    "duplicates_sum_cal = (\n",
    "    duplicates[['SUMMARY', 'CALENDAR']]\n",
    "    .drop_duplicates()\n",
    "    .groupby('SUMMARY')\n",
    "    .filter(lambda x: x['CALENDAR'].nunique() > 1)\n",
    "    .sort_values(by=['SUMMARY', 'CALENDAR'], ascending=[True, True])\n",
    ")\n",
    "print(f\"Quantidade de duplicatas encontradas: {duplicates_sum_cal.shape[0]}\")\n",
    "print(f\"Duplicatas encontradas:\\n{duplicates_sum_cal}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13d1c931",
   "metadata": {},
   "source": [
    "## Verificando valores parecidos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cab2cf2b",
   "metadata": {},
   "source": [
    "### Passando o valor 'Alessandra' da coluna SUMMARY para 'Psic√≥loga'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "6c0224af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantidade de valores √∫nicos antes da unifica√ß√£o:\n",
      "Valores √∫nicos antes da unifica√ß√£o: 376\n",
      "=== TROCANDO DE \"Alessandra\" para \"Psiquiatra\" ===\n",
      "Quantidade de valores √∫nicos antes da unifica√ß√£o:\n",
      "Valores √∫nicos antes da unifica√ß√£o: 375\n",
      "Valores que come√ßam com 'psi' antes da unifica√ß√£o: ['Psiquiatra' 'Psic√≥loga' 'Psic√≥logo']\n",
      "=== TROCANDO DE \"Psic√≥loga\" para \"Psic√≥logo\" ===\n",
      "Valores que come√ßam com 'psi' depois da unifica√ß√£o: ['Psiquiatra' 'Psic√≥logo']\n"
     ]
    }
   ],
   "source": [
    "print('Quantidade de valores √∫nicos antes da unifica√ß√£o:')\n",
    "print(f\"Valores √∫nicos antes da unifica√ß√£o: {df['SUMMARY'].nunique()}\")\n",
    "\n",
    "print('=== TROCANDO DE \"Alessandra\" para \"Psiquiatra\" ===')\n",
    "df.loc[df['SUMMARY'] == 'Alessandra', 'SUMMARY'] = 'Psiquiatra'\n",
    "\n",
    "print('Quantidade de valores √∫nicos antes da unifica√ß√£o:')\n",
    "print(f\"Valores √∫nicos antes da unifica√ß√£o: {df['SUMMARY'].nunique()}\")\n",
    "\n",
    "\n",
    "psi_values = df[df['SUMMARY'].str.lower().str.startswith('psi', na=False)]['SUMMARY'].unique()\n",
    "print(f\"Valores que come√ßam com 'psi' antes da unifica√ß√£o: {psi_values}\")\n",
    "\n",
    "print('=== TROCANDO DE \"Psic√≥loga\" para \"Psic√≥logo\" ===')\n",
    "df.loc[df['SUMMARY'] == 'Psic√≥loga', 'SUMMARY'] = 'Psic√≥logo'\n",
    "\n",
    "psi_values = df[df['SUMMARY'].str.lower().str.startswith('psi', na=False)]['SUMMARY'].unique()\n",
    "print(f\"Valores que come√ßam com 'psi' depois da unifica√ß√£o: {psi_values}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47ababe5",
   "metadata": {},
   "source": [
    "# Exportar DataFrame completo para CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "5a4b3e16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== SALVANDO DATASET PROCESSADO ===\n",
      "‚úÖ Dataset processado salvo em: ../data/tasks_processed.csv\n",
      "\n",
      "=== ESTAT√çSTICAS FINAIS ===\n",
      "Total de registros: 7232\n",
      "Categorias √∫nicas: 13\n"
     ]
    }
   ],
   "source": [
    "# # Salvar dataset processado\n",
    "print(\"=== SALVANDO DATASET PROCESSADO ===\")\n",
    "\n",
    "# Salvar como CSV processado\n",
    "output_path = '../data/tasks_processed.csv'\n",
    "df.to_csv(output_path, index=False, encoding='utf-8')\n",
    "print(f\"‚úÖ Dataset processado salvo em: {output_path}\")\n",
    "\n",
    "# Estat√≠sticas finais\n",
    "print(f\"\\n=== ESTAT√çSTICAS FINAIS ===\")\n",
    "print(f\"Total de registros: {len(df)}\")\n",
    "print(f\"Categorias √∫nicas: {df['CALENDAR'].nunique()}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm-task-scheduler-py3.13",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
