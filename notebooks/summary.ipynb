{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "379d5361",
   "metadata": {},
   "source": [
    "# Pr√© processamento da coluna SUMMARY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "29fcfc92",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import unicodedata\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "8fed6f22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV carregado com engine C! 4463 linhas encontradas.\n",
      "‚úÖ Colunas de data convertidas para datetime\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    df = pd.read_csv(\n",
    "        '../data/new_tasks.csv',\n",
    "        encoding='utf-8',\n",
    "        sep=\",\",\n",
    "    )\n",
    "    print(f\"CSV carregado com engine C! {len(df)} linhas encontradas.\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Erro ao ler CSV: {e}\")\n",
    "\n",
    "# Converter colunas de data para datetime\n",
    "df['DTSTART'] = pd.to_datetime(df['DTSTART'])\n",
    "df['DTEND'] = pd.to_datetime(df['DTEND'])\n",
    "df['CREATED'] = pd.to_datetime(df['CREATED'])\n",
    "print(\"‚úÖ Colunas de data convertidas para datetime\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "0a06b66e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== INFORMA√á√ïES B√ÅSICAS DO DATASET ===\n",
      "Shape: (4463, 6)\n",
      "Colunas: ['SUMMARY', 'DTSTART', 'DTEND', 'CALENDAR', 'DURATION', 'CREATED']\n",
      "Tipos de dados:\n",
      "SUMMARY             object\n",
      "DTSTART     datetime64[ns]\n",
      "DTEND       datetime64[ns]\n",
      "CALENDAR            object\n",
      "DURATION           float64\n",
      "CREATED     datetime64[ns]\n",
      "dtype: object\n",
      "\n",
      "Resumo da coluna SUMMARY:\n",
      "  - Tipo de dado: object\n",
      "  - Valores √∫nicos: 372\n",
      "  - Valores nulos: 0\n",
      "  - Primeiros 5 valores:\n",
      "0     üç≥\n",
      "1     üßã\n",
      "2    üçΩÔ∏è\n",
      "3     ü•™\n",
      "4     üçå\n",
      "Name: SUMMARY, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Verificar informa√ß√µes b√°sicas do dataset\n",
    "print(\"=== INFORMA√á√ïES B√ÅSICAS DO DATASET ===\")\n",
    "print(f\"Shape: {df.shape}\")\n",
    "print(f\"Colunas: {df.columns.tolist()}\")\n",
    "print(f\"Tipos de dados:\\n{df.dtypes}\")\n",
    "\n",
    "# Informa√ß√µes apenas da coluna SUMMARY\n",
    "print(f\"\\nResumo da coluna SUMMARY:\")\n",
    "print(f\"  - Tipo de dado: {df['SUMMARY'].dtype}\")\n",
    "print(f\"  - Valores √∫nicos: {df['SUMMARY'].nunique()}\")\n",
    "print(f\"  - Valores nulos: {df['SUMMARY'].isnull().sum()}\")\n",
    "print(f\"  - Primeiros 5 valores:\\n{df['SUMMARY'].head()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f16a371f",
   "metadata": {},
   "source": [
    "### An√°lise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "2cd70207",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== AN√ÅlISE DA COLUNA SUMMARY ===\n",
      "Quantidade de valores √∫nicos: 372\n"
     ]
    }
   ],
   "source": [
    "print(\"=== AN√ÅlISE DA COLUNA SUMMARY ===\")\n",
    "\n",
    "print(f\"Quantidade de valores √∫nicos: {df['SUMMARY'].nunique()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03bbf7f2",
   "metadata": {},
   "source": [
    "### Corrigindo os valores que est√£o com EMOJI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "c1aa3804",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     üç≥\n",
      "1     üßã\n",
      "2    üçΩÔ∏è\n",
      "3     ü•™\n",
      "4     üçå\n",
      "5    üçΩÔ∏è\n",
      "6     üç≥\n",
      "7     üßã\n",
      "Name: SUMMARY, dtype: object\n",
      "0      cafe da manha\n",
      "1    lanche da manha\n",
      "2             almoco\n",
      "3    lanche da tarde\n",
      "4         pre-treino\n",
      "5             jantar\n",
      "6      cafe da manha\n",
      "7    lanche da manha\n",
      "Name: SUMMARY, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(df['SUMMARY'].head(8))\n",
    "\n",
    "# üßã: lanche da manha\n",
    "# üçΩÔ∏è e antes das 18:00: almoco\n",
    "# ü•™: lanche da tarde\n",
    "# üçå: pre-treino\n",
    "# üçΩÔ∏è e exatamente ou depois das 18:00: jantar\n",
    "\n",
    "df.loc[df['SUMMARY'] == 'üç≥', 'SUMMARY'] = 'cafe da manha'\n",
    "df.loc[df['SUMMARY'] == 'üßã', 'SUMMARY'] = 'lanche da manha'\n",
    "# Almo√ßo: emoji üçΩÔ∏è e come√ßa antes das 18h\n",
    "df.loc[(df['SUMMARY'] == 'üçΩÔ∏è') & (pd.to_datetime(df['DTSTART']).dt.hour < 18), 'SUMMARY'] = 'almoco'\n",
    "df.loc[df['SUMMARY'] == 'ü•™', 'SUMMARY'] = 'lanche da tarde'\n",
    "df.loc[df['SUMMARY'] == 'üçå', 'SUMMARY'] = 'pre-treino'\n",
    "df.loc[(df['SUMMARY'] == 'üçΩÔ∏è') & (pd.to_datetime(df['DTSTART']).dt.hour >= 18), 'SUMMARY'] = 'jantar'\n",
    "\n",
    "print(df['SUMMARY'].head(8))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dbda371",
   "metadata": {},
   "source": [
    "## Limpando"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "3ddcfa37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Avalia√ß√£o da coluna SUMMARY antes da normaliza√ß√£o ===\n",
      "Valores √∫nicos: 373\n",
      "Exemplos aleat√≥rios: ['Pulo Big Jump', 'INF1301 - Relat√≥rio Plano de A√ß√£o', 'Zion', 'Niver Giovanna Lopes', 'Avalia√ß√£o 4 √Ålgebra']\n",
      "\n",
      "=== Avalia√ß√£o da coluna SUMMARY depois da normaliza√ß√£o ===\n",
      "Valores √∫nicos: 369\n",
      "Exemplos aleat√≥rios: ['festa niver', 'p1 inf1018', 'zion', 'formatura renata', 'tete 2 maple algebra']\n"
     ]
    }
   ],
   "source": [
    "def normalize_text(text):\n",
    "    if pd.isnull(text):\n",
    "        return \"\"\n",
    "    # Lowercase\n",
    "    text = text.lower()\n",
    "    # Remove accents\n",
    "    text = unicodedata.normalize('NFKD', text).encode('ASCII', 'ignore').decode('utf-8')\n",
    "    # Remove extra spaces\n",
    "    text = ' '.join(text.split())\n",
    "    return text\n",
    "\n",
    "# Avalia√ß√£o antes da normaliza√ß√£o\n",
    "print(\"=== Avalia√ß√£o da coluna SUMMARY antes da normaliza√ß√£o ===\")\n",
    "print(f\"Valores √∫nicos: {df['SUMMARY'].nunique()}\")\n",
    "print(f\"Exemplos aleat√≥rios: {df['SUMMARY'].drop_duplicates().sample(5, random_state=42).tolist()}\")\n",
    "\n",
    "df['SUMMARY'] = df['SUMMARY'].apply(normalize_text)\n",
    "\n",
    "# Avalia√ß√£o depois da normaliza√ß√£o\n",
    "print(\"\\n=== Avalia√ß√£o da coluna SUMMARY depois da normaliza√ß√£o ===\")\n",
    "print(f\"Valores √∫nicos: {df['SUMMARY'].nunique()}\")\n",
    "print(f\"Exemplos aleat√≥rios: {df['SUMMARY'].drop_duplicates().sample(5, random_state=42).tolist()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6e8396b",
   "metadata": {},
   "source": [
    "### Dropando valores que n√£o s√£o necess√°rios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "7afa404f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numero de linhas antes de retirar RescueTime: 4463\n",
      "Numero de linhas depois de retirar RescueTime: 4418\n"
     ]
    }
   ],
   "source": [
    "print('Numero de linhas antes de retirar RescueTime:', len(df))\n",
    "df = df[df['CALENDAR'] != 'RescueTime']\n",
    "print('Numero de linhas depois de retirar RescueTime:', len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "88ade517",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N√∫mero de linhas antes de retirar o Rotina:  4418\n",
      "N√∫mero de linhas depois de retirar o Rotina:  4372\n"
     ]
    }
   ],
   "source": [
    "print('N√∫mero de linhas antes de retirar o Rotina: ', len(df))\n",
    "df = df[df['CALENDAR'] != 'Rotina']\n",
    "print('N√∫mero de linhas depois de retirar o Rotina: ', len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "2210e6fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N√∫mero de linhas antes de retirar parabens!:  4372\n",
      "N√∫mero de linhas depois de retirar parabens!:  4372\n"
     ]
    }
   ],
   "source": [
    "print('N√∫mero de linhas antes de retirar parabens!: ', len(df))\n",
    "df = df[df['SUMMARY'] != 'parabens']\n",
    "print('N√∫mero de linhas depois de retirar parabens!: ', len(df))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2b76e0d",
   "metadata": {},
   "source": [
    "### Tratando valores da coluna SUMMARY que possuem dois valores na coluna CALENDAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "f2b23e31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== TRATANDO Duplicatas da coluna SUMMARY ===\n",
      "Valores de CALENDAR para \"Academia\": ['Exerc√≠cios']\n",
      "Valores de CALENDAR para \"Aldeia\": ['Social']\n",
      "Valores de CALENDAR para \"Alessandra\": ['Sa√∫de']\n",
      "Valores de CALENDAR para \"Aula\": ['PUC']\n",
      "Valores de CALENDAR para \"BD: T2 G2\": ['Exames']\n",
      "Valores de CALENDAR para \"BIRUSAMBA DE VER√ÉO\": ['Social']\n",
      "Valores de CALENDAR para \"De-Para\": ['PUC']\n",
      "Valores de CALENDAR para \"Muay Thai\": ['Exerc√≠cios']\n",
      "Valores de CALENDAR para \"Psic√≥loga\": ['Sa√∫de']\n",
      "Valores de CALENDAR para \"SO: P1\": ['Exames']\n",
      "Valores de CALENDAR para \"Itaipava\": ['Social']\n"
     ]
    }
   ],
   "source": [
    "# Coluna SUMMARY possui 30 valores que tem duas varia√ß√µes em 'CALENDAR'\n",
    "print(\"=== TRATANDO Duplicatas da coluna SUMMARY ===\")\n",
    "df['CALENDAR'] = df['CALENDAR'].replace('PUC üëª', 'PUC')\n",
    "\n",
    "# Corrigindo os valores duplicados de 'Academia'\n",
    "df.loc[(df['SUMMARY'] == 'academia') & (df['CALENDAR'] == 'Pessoal'), 'CALENDAR'] = 'Exerc√≠cios' # 2\n",
    "print(f'Valores de CALENDAR para \"Academia\": {df.loc[df[\"SUMMARY\"] == \"academia\", \"CALENDAR\"].unique()}')\n",
    "\n",
    "# Corrigindo os valores duplicados de 'Aldeia'\n",
    "df.loc[(df['SUMMARY'] == 'aldeia') & (df['CALENDAR'] == 'Pessoal'), 'CALENDAR'] = 'Social' # 2\n",
    "print(f'Valores de CALENDAR para \"Aldeia\": {df.loc[df[\"SUMMARY\"] == \"aldeia\", \"CALENDAR\"].unique()}')\n",
    "\n",
    "# Corrigindo os valores duplicados de 'Alessandra'\n",
    "df.loc[(df['SUMMARY'] == 'alessandra') & (df['CALENDAR'] == 'Compromisso'), 'CALENDAR'] = 'Sa√∫de' # 2\n",
    "print(f'Valores de CALENDAR para \"Alessandra\": {df.loc[df[\"SUMMARY\"] == \"alessandra\", \"CALENDAR\"].unique()}')\n",
    "\n",
    "# Corrigindo os valores duplicados de 'Aula'\n",
    "df.loc[(df['SUMMARY'] == 'aula') & (df['CALENDAR'] == 'Pessoal'), 'CALENDAR'] = 'PUC' # 2\n",
    "print(f'Valores de CALENDAR para \"Aula\": {df.loc[df[\"SUMMARY\"] == \"aula\", \"CALENDAR\"].unique()}')\n",
    "\n",
    "# Corrigindo os valores duplicados de 'BD: T2 G2'\n",
    "df.loc[(df['SUMMARY'] == 'bd: t2 g2') & (df['CALENDAR'] == 'PUC'), 'CALENDAR'] = 'Exames' # 2\n",
    "print(f'Valores de CALENDAR para \"BD: T2 G2\": {df.loc[df[\"SUMMARY\"] == \"bd: t2 g2\", \"CALENDAR\"].unique()}')\n",
    "\n",
    "# Corrigindo os valores duplicados de 'BIRUSAMBA DE VER√ÉO'\n",
    "df.loc[(df['SUMMARY'] == 'birusamba de verao'), 'CALENDAR'] = 'Social' # 2\n",
    "print(f'Valores de CALENDAR para \"BIRUSAMBA DE VER√ÉO\": {df.loc[df[\"SUMMARY\"] == \"birusamba de verao\", \"CALENDAR\"].unique()}')\n",
    "\n",
    "# Corrigindo os valores duplicados de De-Para\n",
    "df.loc[(df['SUMMARY'] == 'de-para') & (df['CALENDAR'] == 'Exames'), 'CALENDAR'] = 'PUC' # 2\n",
    "print(f'Valores de CALENDAR para \"De-Para\": {df.loc[df[\"SUMMARY\"] == \"de-para\", \"CALENDAR\"].unique()}')\n",
    "\n",
    "# Corrigindo os valores duplicados de 'Muay Thai'\n",
    "df.loc[(df['SUMMARY'] == 'muay thai') & (df['CALENDAR'] == 'Pessoal'), 'CALENDAR'] = 'Exerc√≠cios' # 2\n",
    "print(f'Valores de CALENDAR para \"Muay Thai\": {df.loc[df[\"SUMMARY\"] == \"muay thai\", \"CALENDAR\"].unique()}')\n",
    "\n",
    "# Corrigindo valores duplicados de 'Psic√≥loga'\n",
    "df.loc[(df['SUMMARY'] == 'psicologa') & (df['CALENDAR'] == 'Compromisso'), 'CALENDAR'] = 'Sa√∫de' # 2\n",
    "print(f'Valores de CALENDAR para \"Psic√≥loga\": {df.loc[df[\"SUMMARY\"] == \"psicologa\", \"CALENDAR\"].unique()}')\n",
    "\n",
    "# Corrigindo valores duplicados de 'SO: P1' # 2\n",
    "df.loc[(df['SUMMARY'] == 'so: p1') & (df['CALENDAR'] == 'PUC'), 'CALENDAR'] = 'Exames' # 2\n",
    "print(f'Valores de CALENDAR para \"SO: P1\": {df.loc[df[\"SUMMARY\"] == \"so: p1\", \"CALENDAR\"].unique()}')\n",
    "\n",
    "# Corrigindo valores duplicados de 'Itaipava'\n",
    "df.loc[(df['SUMMARY'] == 'itaipava') & (df['CALENDAR'] == 'Pessoal'), 'CALENDAR'] = 'Social' # 2\n",
    "print(f'Valores de CALENDAR para \"Itaipava\": {df.loc[df[\"SUMMARY\"] == \"itaipava\", \"CALENDAR\"].unique()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "2b8fc837",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== ENCONTRO DE DUPLICATAS DA COLUNA SUMMARY ===\n",
      "Quantidade de duplicatas encontradas: 2\n",
      "Duplicatas encontradas:\n",
      "     SUMMARY     CALENDAR\n",
      "2     almoco  Alimenta√ß√£o\n",
      "2770  almoco      Pessoal\n"
     ]
    }
   ],
   "source": [
    "print(\"=== ENCONTRO DE DUPLICATAS DA COLUNA SUMMARY ===\")\n",
    "duplicates = df[df.duplicated(subset='SUMMARY', keep=False)]\n",
    "# Seleciona duplicatas de SUMMARY que aparecem em mais de um CALENDAR\n",
    "duplicates_sum_cal = (\n",
    "    duplicates[['SUMMARY', 'CALENDAR']]\n",
    "    .drop_duplicates()\n",
    "    .groupby('SUMMARY')\n",
    "    .filter(lambda x: x['CALENDAR'].nunique() > 1)\n",
    "    .sort_values(by=['SUMMARY', 'CALENDAR'], ascending=[True, True])\n",
    ")\n",
    "print(f\"Quantidade de duplicatas encontradas: {duplicates_sum_cal.shape[0]}\")\n",
    "print(f\"Duplicatas encontradas:\\n{duplicates_sum_cal}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13d1c931",
   "metadata": {},
   "source": [
    "## Verificando valores parecidos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cab2cf2b",
   "metadata": {},
   "source": [
    "### Passando o valor 'Alessandra' da coluna SUMMARY para 'Psic√≥loga'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "6c0224af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantidade de valores √∫nicos antes da unifica√ß√£o: 324\n",
      "=== TROCANDO DE \"alessandra\" para \"psiquiatra\" ===\n",
      "Quantidade de valores √∫nicos depois da unifica√ß√£o: 323\n",
      "\n",
      "Valores que come√ßam com 'psi' antes da unifica√ß√£o: ['psiquiatra' 'psicologa' 'psicologo']\n",
      "=== TROCANDO DE \"psicologa\" para \"psicologo\" ===\n",
      "Valores que come√ßam com 'psi' depois da unifica√ß√£o: ['psiquiatra' 'psicologo']\n"
     ]
    }
   ],
   "source": [
    "print(f\"Quantidade de valores √∫nicos antes da unifica√ß√£o: {df['SUMMARY'].nunique()}\")\n",
    "\n",
    "print('=== TROCANDO DE \"alessandra\" para \"psiquiatra\" ===')\n",
    "df.loc[df['SUMMARY'] == 'alessandra', 'SUMMARY'] = 'psiquiatra'\n",
    "\n",
    "print(f\"Quantidade de valores √∫nicos depois da unifica√ß√£o: {df['SUMMARY'].nunique()}\")\n",
    "\n",
    "\n",
    "psi_values = df[df['SUMMARY'].str.lower().str.startswith('psi', na=False)]['SUMMARY'].unique()\n",
    "print(f\"\\nValores que come√ßam com 'psi' antes da unifica√ß√£o: {psi_values}\")\n",
    "\n",
    "print('=== TROCANDO DE \"psicologa\" para \"psicologo\" ===')\n",
    "df.loc[df['SUMMARY'] == 'psicologa', 'SUMMARY'] = 'psicologo'\n",
    "\n",
    "psi_values = df[df['SUMMARY'].str.lower().str.startswith('psi', na=False)]['SUMMARY'].unique()\n",
    "print(f\"Valores que come√ßam com 'psi' depois da unifica√ß√£o: {psi_values}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c3288d3",
   "metadata": {},
   "source": [
    "## Melhorando valores com INF, MAT ou ADM no inicio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e95ec778",
   "metadata": {},
   "source": [
    "### Verificando todos os valores que possuem inf, mat ou adm no inicio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "577e1cc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Avaliando valores que come√ßam com \"inf\", \"mat\" ou \"adm\"\n",
      "Quantidade de valores √∫nicos: 33\n",
      "Valores:\n",
      "SUMMARY\n",
      "inf1410 - gerenc proj inf                     39\n",
      "adm1019 - intr. financas                      38\n",
      "inf1629 - p. eng. de software                 38\n",
      "mat4162 - calculo ii                          38\n",
      "inf1608 - analise numerica                    38\n",
      "inf1307 - games                               36\n",
      "inf1316 - so                                  36\n",
      "inf1771 - ia                                  36\n",
      "inf1403 - ihc                                 35\n",
      "inf1022 - als                                 35\n",
      "inf1350 - prog sis reat                       34\n",
      "inf1027 - teste e medicao de software         33\n",
      "inf1036 - prob comp                           32\n",
      "inf1640 - redes de computadores               31\n",
      "inf1636 - programacao orientada a objetos     31\n",
      "inf1631 - estruturas discretas                31\n",
      "inf1028 - projeto e construcao de sistemas    30\n",
      "inf1721 - aa                                  30\n",
      "inf1032 - ciencia de dados                    29\n",
      "inf1010 - eda                                 23\n",
      "inf1383 - bancos de dados                     19\n",
      "inf1314 - startup ia                          19\n",
      "inf1338 - llm                                 18\n",
      "mat1260 - algebra linear 1                     8\n",
      "inf1018 - software basico                      8\n",
      "inf1301 - programacao modular                  6\n",
      "inf1022 - analisadores lex. e sint.            4\n",
      "matricula puc                                  4\n",
      "mat1162 - calculo a varias variaveis i         3\n",
      "inf2471 - prob comp                            2\n",
      "inf1018 - monitoria                            1\n",
      "inf1920 - aula expositiva                      1\n",
      "inf1301 - relatorio plano de acao              1\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print('=== Avaliando valores que come√ßam com \"inf\", \"mat\" ou \"adm\"')\n",
    "\n",
    "inf_mat_values = df.loc[\n",
    "    df['SUMMARY'].str.lower().str.startswith('adm', na=False) |\n",
    "    df['SUMMARY'].str.lower().str.startswith('inf', na=False) |\n",
    "    df['SUMMARY'].str.lower().str.startswith('mat', na=False),\n",
    "    'SUMMARY'\n",
    "]\n",
    "print(f'Quantidade de valores √∫nicos: {inf_mat_values.nunique()}')\n",
    "\n",
    "print(f'Valores:\\n{inf_mat_values.value_counts()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ae17424",
   "metadata": {},
   "source": [
    "### Retirando INF2471 - Prob Comp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "afda6568",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N√∫mero de linhas antes de retirar inf2471 - prob comp:  4372\n",
      "N√∫mero de linhas depois de retirar inf2471 - prob comp:  4370\n"
     ]
    }
   ],
   "source": [
    "print('N√∫mero de linhas antes de retirar inf2471 - prob comp: ', len(df))\n",
    "df = df[df['SUMMARY'] != 'inf2471 - prob comp']\n",
    "print('N√∫mero de linhas depois de retirar inf2471 - prob comp: ', len(df))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d15c9bcf",
   "metadata": {},
   "source": [
    "### Retirando MAT1162 - CALCULO A VARIAS VARIAVEIS I"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "767d54de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N√∫mero de linhas antes de retirar mat1162 - calculo a varias variaveis i:  4370\n",
      "N√∫mero de linhas depois de retirar mat1162 - calculo a varias variaveis i:  4367\n"
     ]
    }
   ],
   "source": [
    "print('N√∫mero de linhas antes de retirar mat1162 - calculo a varias variaveis i: ', len(df))\n",
    "df = df[df['SUMMARY'] != 'mat1162 - calculo a varias variaveis i']\n",
    "print('N√∫mero de linhas depois de retirar mat1162 - calculo a varias variaveis i: ', len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "c98bce17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Expans√£o de abrevia√ß√µes conclu√≠da - tudo em min√∫sculo!\n"
     ]
    }
   ],
   "source": [
    "# Corrigir primeiro c√≥digo que j√° estava sendo tratado\n",
    "df.loc[df['SUMMARY'] == 'inf1410 - gerenc proj inf', 'SUMMARY'] = 'inf1410 - gerencia de projetos de informatica'\n",
    "\n",
    "# INF1629 - P. Eng. de Software\n",
    "df.loc[df['SUMMARY'] == 'inf1629 - p. eng. de software', 'SUMMARY'] = 'inf1629 - principios de engenharia de software'\n",
    "\n",
    "# INF1314 - Startup IA\n",
    "df.loc[df['SUMMARY'] == 'inf1314 - startup ia', 'SUMMARY'] = 'inf1314 - gerando startup com inteligencia artificial'\n",
    "\n",
    "# INF1771 - IA\n",
    "df.loc[df['SUMMARY'] == 'inf1771 - ia', 'SUMMARY'] = 'inf1771 - inteligencia artificial'\n",
    "\n",
    "# INF1307 - Games\n",
    "df.loc[df['SUMMARY'] == 'inf1307 - games', 'SUMMARY'] = 'inf1307 - desenvolvimento de jogos'\n",
    "\n",
    "# INF1316 - SO\n",
    "df.loc[df['SUMMARY'] == 'inf1316 - so', 'SUMMARY'] = 'inf1316 - sistemas operacionais'\n",
    "\n",
    "# INF1403 - IHC\n",
    "df.loc[df['SUMMARY'] == 'inf1403 - ihc', 'SUMMARY'] = 'inf1403 - interacao humano computador'\n",
    "\n",
    "# INF1022 - ALS\n",
    "df.loc[df['SUMMARY'] == 'inf1022 - als', 'SUMMARY'] = 'inf1022 - analisadores lexicos e sintaticos'\n",
    "\n",
    "# INF1350 - Prog Sis Reat\n",
    "df.loc[df['SUMMARY'] == 'inf1350 - prog sis reat', 'SUMMARY'] = 'inf1350 - programacao de sistemas reativos'\n",
    "\n",
    "# INF1036 - Prob Comp\n",
    "df.loc[df['SUMMARY'] == 'inf1036 - prob comp', 'SUMMARY'] = 'inf1036 - probabilidade computacional'\n",
    "\n",
    "# INF1721 - AA\n",
    "df.loc[df['SUMMARY'] == 'inf1721 - aa', 'SUMMARY'] = 'inf1721 - analise de algoritmos'\n",
    "\n",
    "# INF1010 - EDA\n",
    "df.loc[df['SUMMARY'] == 'inf1010 - eda', 'SUMMARY'] = 'inf1010 - estruturas de dados avan√ßadas'\n",
    "\n",
    "# INF1338 - LLM\n",
    "df.loc[df['SUMMARY'] == 'inf1338 - llm', 'SUMMARY'] = 'inf1338 - large language models'\n",
    "\n",
    "# INF1022 - Analisadores L√©x. e Sint.\n",
    "df.loc[df['SUMMARY'] == 'inf1022 - analisadores lex. e sint.', 'SUMMARY'] = 'inf1022 - analisadores lexicos e sintaticos'\n",
    "\n",
    "df.loc[df['SUMMARY'] == 'adm1019 - intr. financas', 'SUMMARY'] = 'adm1019 - introducao a finan√ßas'\n",
    "\n",
    "print('‚úÖ Expans√£o de abrevia√ß√µes conclu√≠da - tudo em min√∫sculo!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b60e317",
   "metadata": {},
   "source": [
    "### Verificando novamente os valores com INF, MAT ou ADM no inicio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "4ca40727",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Avaliando valores que come√ßam com \"inf\", \"mat\" ou \"adm\"\n",
      "Quantidade de valores √∫nicos: 30\n",
      "Valores:\n",
      "SUMMARY\n",
      "inf1410 - gerencia de projetos de informatica            39\n",
      "inf1022 - analisadores lexicos e sintaticos              39\n",
      "adm1019 - introducao a finan√ßas                          38\n",
      "inf1629 - principios de engenharia de software           38\n",
      "mat4162 - calculo ii                                     38\n",
      "inf1608 - analise numerica                               38\n",
      "inf1771 - inteligencia artificial                        36\n",
      "inf1316 - sistemas operacionais                          36\n",
      "inf1307 - desenvolvimento de jogos                       36\n",
      "inf1403 - interacao humano computador                    35\n",
      "inf1350 - programacao de sistemas reativos               34\n",
      "inf1027 - teste e medicao de software                    33\n",
      "inf1036 - probabilidade computacional                    32\n",
      "inf1631 - estruturas discretas                           31\n",
      "inf1636 - programacao orientada a objetos                31\n",
      "inf1640 - redes de computadores                          31\n",
      "inf1028 - projeto e construcao de sistemas               30\n",
      "inf1721 - analise de algoritmos                          30\n",
      "inf1032 - ciencia de dados                               29\n",
      "inf1010 - estruturas de dados avan√ßadas                  23\n",
      "inf1383 - bancos de dados                                19\n",
      "inf1314 - gerando startup com inteligencia artificial    19\n",
      "inf1338 - large language models                          18\n",
      "mat1260 - algebra linear 1                                8\n",
      "inf1018 - software basico                                 8\n",
      "inf1301 - programacao modular                             6\n",
      "matricula puc                                             4\n",
      "inf1018 - monitoria                                       1\n",
      "inf1920 - aula expositiva                                 1\n",
      "inf1301 - relatorio plano de acao                         1\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print('=== Avaliando valores que come√ßam com \"inf\", \"mat\" ou \"adm\"')\n",
    "\n",
    "inf_mat_values = df.loc[\n",
    "    df['SUMMARY'].str.lower().str.startswith('adm', na=False) |\n",
    "    df['SUMMARY'].str.lower().str.startswith('inf', na=False) |\n",
    "    df['SUMMARY'].str.lower().str.startswith('mat', na=False),\n",
    "    'SUMMARY'\n",
    "]\n",
    "print(f'Quantidade de valores √∫nicos: {inf_mat_values.nunique()}')\n",
    "\n",
    "print(f'Valores:\\n{inf_mat_values.value_counts()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af3ff7d3",
   "metadata": {},
   "source": [
    "## Verbalizar tarefas e anonimizar pessoas (com llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "e8a7f26a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exportar tuplas √∫nicas de (SUMMARY, CALENDAR) para CSV\n",
    "# df[['SUMMARY', 'CALENDAR']].drop_duplicates().to_csv('../data/summary_calendar_unique.csv', index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eebdfca6",
   "metadata": {},
   "source": [
    "### Colocando as tarefas nos (SUMMARY, CALENDAR) √∫nicos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "dc873f14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== INTEGRANDO TASKS VERBALIZADAS ===\n",
      "Tasks verbalizadas carregadas: 320 registros\n",
      "Mapeamento criado para 320 tuplas √∫nicas\n",
      "\n",
      "Resultados do mapeamento:\n",
      "‚úÖ Registros com task atribu√≠da: 4330\n",
      "‚ùå Registros sem task: 37\n",
      "üìä Taxa de sucesso: 99.15%\n",
      "\n",
      "=== EXEMPLOS DOS DADOS INTEGRADOS ===\n",
      "           SUMMARY     CALENDAR                 TASK\n",
      "0    cafe da manha  Alimenta√ß√£o  Tomar caf√© da manh√£\n",
      "1  lanche da manha  Alimenta√ß√£o     Lanchar de manh√£\n",
      "2           almoco  Alimenta√ß√£o              Almo√ßar\n",
      "3  lanche da tarde  Alimenta√ß√£o      Lanchar √† tarde\n",
      "4       pre-treino  Alimenta√ß√£o   Tomar o pr√©-treino\n",
      "5           jantar  Alimenta√ß√£o               Jantar\n",
      "6    cafe da manha  Alimenta√ß√£o  Tomar caf√© da manh√£\n",
      "7  lanche da manha  Alimenta√ß√£o     Lanchar de manh√£\n",
      "8           almoco  Alimenta√ß√£o              Almo√ßar\n",
      "9  lanche da tarde  Alimenta√ß√£o      Lanchar √† tarde\n",
      "\n",
      "=== REGISTROS N√ÉO MAPEADOS ===\n",
      "Tuplas √∫nicas n√£o mapeadas: 35\n",
      "                                  SUMMARY     CALENDAR\n",
      "1245                                   rm  Compromisso\n",
      "1248                                 zion  Compromisso\n",
      "1289                          visita rede  Compromisso\n",
      "1291                  mago da musica link  Compromisso\n",
      "1376                    pcs: apresentacao       Exames\n",
      "1379                               ed: p1       Exames\n",
      "1381                 pcs: apresentacao g2       Exames\n",
      "1383                  cd: apresentacao g2       Exames\n",
      "1385                               ed: p2       Exames\n",
      "1386                          ed: lista 4       Exames\n",
      "1392                             psr: mp1       Exames\n",
      "1405                    projeto final psr       Exames\n",
      "1445                        viviane nutri        Sa√∫de\n",
      "1446                           dra. vania        Sa√∫de\n",
      "1711                       academia ideal   Exerc√≠cios\n",
      "2281                        aula da liane      Pessoal\n",
      "2282                       casa do felipe      Pessoal\n",
      "2326                             amazonia      Pessoal\n",
      "2775                           primo rico      Pessoal\n",
      "2778   reuniao de cronograma do acessorio      Pessoal\n",
      "2779                      corte masculino      Pessoal\n",
      "2784            call checkpoint acessorio      Pessoal\n",
      "2788                   gravacao acessorio      Pessoal\n",
      "2789                                 fone      Pessoal\n",
      "2797                avaliacao imobiliaria      Pessoal\n",
      "2798                       wwdc ilearning      Pessoal\n",
      "2800  mentoria inversu (felipe gameleira)      Pessoal\n",
      "2802  mentoria inversu - felipe gameleira      Pessoal\n",
      "3746                       ingresso harry       Social\n",
      "3749                                 thor       Social\n",
      "3750                         the avengers       Social\n",
      "3751                      rafael portugal       Social\n",
      "3767                        pulo big jump       Social\n",
      "3768                       resenha felipe       Social\n",
      "3782                             festa re       Social\n"
     ]
    }
   ],
   "source": [
    "# Carregar as tasks verbalizadas e integrar com o dataset original\n",
    "print(\"=== INTEGRANDO TASKS VERBALIZADAS ===\")\n",
    "\n",
    "# Carregar o arquivo com as tasks verbalizadas\n",
    "formatted_tasks_df = pd.read_csv('../data/fixed/formatted_tasks.csv', encoding='utf-8')\n",
    "print(f\"Tasks verbalizadas carregadas: {len(formatted_tasks_df)} registros\")\n",
    "\n",
    "# Criar um dicion√°rio para mapear (SUMMARY, CALENDAR) -> TASK\n",
    "task_mapping = {}\n",
    "for _, row in formatted_tasks_df.iterrows():\n",
    "    key = (row['SUMMARY'], row['CALENDAR'])\n",
    "    task_mapping[key] = row['TASK']\n",
    "\n",
    "print(f\"Mapeamento criado para {len(task_mapping)} tuplas √∫nicas\")\n",
    "\n",
    "# Adicionar a coluna TASK ao dataset original\n",
    "df['TASK'] = df.apply(lambda row: task_mapping.get((row['SUMMARY'], row['CALENDAR']), ''), axis=1)\n",
    "\n",
    "# Verificar quantos registros foram mapeados\n",
    "mapped_count = len(df[df['TASK'] != ''])\n",
    "unmapped_count = len(df[df['TASK'] == ''])\n",
    "\n",
    "print(f\"\\nResultados do mapeamento:\")\n",
    "print(f\"‚úÖ Registros com task atribu√≠da: {mapped_count}\")\n",
    "print(f\"‚ùå Registros sem task: {unmapped_count}\")\n",
    "print(f\"üìä Taxa de sucesso: {(mapped_count / len(df) * 100):.2f}%\")\n",
    "\n",
    "# Mostrar exemplos dos dados integrados\n",
    "print(f\"\\n=== EXEMPLOS DOS DADOS INTEGRADOS ===\")\n",
    "print(df[['SUMMARY', 'CALENDAR', 'TASK']].head(10))\n",
    "\n",
    "# Verificar se h√° registros n√£o mapeados\n",
    "if unmapped_count > 0:\n",
    "    print(f\"\\n=== REGISTROS N√ÉO MAPEADOS ===\")\n",
    "    # Mostrar todos os n√£o mapeados\n",
    "    unmapped_df = df[df['TASK'] == ''][['SUMMARY', 'CALENDAR']].drop_duplicates()\n",
    "    print(f\"Tuplas √∫nicas n√£o mapeadas: {len(unmapped_df)}\")\n",
    "    print(unmapped_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9adf33a",
   "metadata": {},
   "source": [
    "## Formatar a coluna TASKS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "92f44282",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Antes da normaliza√ß√£o da coluna TASK:\n",
      "['Fazer a prova 1 de INF1018', 'Fazer a prova 3 de c√°lculo', 'Fazer o trabalho 1 de Sistemas Operacionais', 'Fazer bioimped√¢ncia', 'Ir para a aula de inf1316 - sistemas operacionais']\n",
      "Depois da normaliza√ß√£o da coluna TASK:\n",
      "['fazer a prova 1 de inf1018', 'fazer a prova 3 de calculo', 'fazer o trabalho 1 de sistemas operacionais', 'fazer bioimpedancia', 'ir para a aula de inf1316 - sistemas operacionais']\n"
     ]
    }
   ],
   "source": [
    "print('Antes da normaliza√ß√£o da coluna TASK:')\n",
    "# Selecionar exemplos aleat√≥rios para verificar diferen√ßa antes/depois\n",
    "exemplos_antes = df['TASK'].drop_duplicates().sample(5, random_state=42).tolist()\n",
    "print(exemplos_antes)\n",
    "\n",
    "df['TASK'] = df['TASK'].apply(normalize_text)\n",
    "\n",
    "print('Depois da normaliza√ß√£o da coluna TASK:')\n",
    "exemplos_depois = df['TASK'].drop_duplicates().sample(5, random_state=42).tolist()\n",
    "print(exemplos_depois)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76309981",
   "metadata": {},
   "source": [
    "## Descartar tarefas que cobrem o dia inteiro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "ab619ec8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== DESCARTANDO TAREFAS QUE COBREM O DIA INTEIRO ===\n",
      "Tarefas que cobrem o dia inteiro encontradas: 306\n",
      "Total de registros ap√≥s descartar tarefas de 24h: 4061\n"
     ]
    }
   ],
   "source": [
    "print('=== DESCARTANDO TAREFAS QUE COBREM O DIA INTEIRO ===')\n",
    "    # Filtrar tarefas que come√ßam e terminam exatamente √†s 00:00 e duram 24 horas\n",
    "mask = (\n",
    "    (pd.to_datetime(df['DTSTART']).dt.hour == 0) &\n",
    "    (pd.to_datetime(df['DTSTART']).dt.minute == 0) &\n",
    "    (pd.to_datetime(df['DTEND']).dt.hour == 0) &\n",
    "    (pd.to_datetime(df['DTEND']).dt.minute == 0) &\n",
    "    (df['DURATION'] == 24.0)\n",
    ")\n",
    "print(f'Tarefas que cobrem o dia inteiro encontradas: {mask.sum()}')\n",
    "df = df[~mask]\n",
    "print(f'Total de registros ap√≥s descartar tarefas de 24h: {len(df)}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1514b98",
   "metadata": {},
   "source": [
    "## Adicionar colunas de time slot e week of year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "d60c3806",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"TIME_SLOT\"] = df[\"DTSTART\"].dt.weekday * 24 + df[\"DTSTART\"].dt.hour\n",
    "df[\"YEAR_WEEK\"] = df[\"DTSTART\"].dt.year.astype(str) + \"-\" + df[\"DTSTART\"].dt.isocalendar().week.astype(str)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47ababe5",
   "metadata": {},
   "source": [
    "# Exportar DataFrame completo para CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "5a4b3e16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== SALVANDO DATASET PROCESSADO ===\n",
      "‚úÖ Dataset processado salvo em: ../data/tasks_summary.csv\n",
      "\n",
      "=== ESTAT√çSTICAS FINAIS ===\n",
      "Total de registros: 4061\n",
      "Categorias √∫nicas: 11\n"
     ]
    }
   ],
   "source": [
    "# # Salvar dataset processado\n",
    "print(\"=== SALVANDO DATASET PROCESSADO ===\")\n",
    "\n",
    "# Salvar como CSV processado\n",
    "output_path = '../data/tasks_summary.csv'\n",
    "df.to_csv(output_path, index=False, encoding='utf-8')\n",
    "print(f\"‚úÖ Dataset processado salvo em: {output_path}\")\n",
    "\n",
    "# Estat√≠sticas finais\n",
    "print(f\"\\n=== ESTAT√çSTICAS FINAIS ===\")\n",
    "print(f\"Total de registros: {len(df)}\")\n",
    "print(f\"Categorias √∫nicas: {df['CALENDAR'].nunique()}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm-task-scheduler-py3.13",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
